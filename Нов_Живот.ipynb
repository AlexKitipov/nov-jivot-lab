{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZL2pdUhDldqyJ/oBEJPfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexKitipov/nov-jivot-lab/blob/main/%D0%9D%D0%BE%D0%B2_%D0%96%D0%B8%D0%B2%D0%BE%D1%82.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass, os\n",
        "\n",
        "# –ë—ä–ª–≥–∞—Ä—Å–∫–∏: –≤—ä–≤–µ–∂–¥–∞—à —Å–≤–æ—è Personal Access Token, –±–µ–∑ –¥–∞ —Å–µ –ø–æ–∫–∞–∑–≤–∞ –Ω–∞ –µ–∫—Ä–∞–Ω–∞\n",
        "# English: this will prompt you ‚Äî it won‚Äôt echo your token\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub token: ')\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_sdHK2H8tHf",
        "outputId": "449bbed6-a0b2-4aa5-bc5f-cb72df6e5169"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Bulgarian: –∑–∞–º–µ–Ω–∏ YOUR_TOKEN —Å —Ä–µ–∞–ª–Ω–∏—è —Ç–∏ —Ç–æ–∫–µ–Ω\n",
        "# English: you can unregister this cell later\n",
        "os.environ['GITHUB_TOKEN'] = 'YOUR_TOKEN'\n",
        "\n",
        "GITHUB_TOKEN = os.environ['GITHUB_TOKEN']\n"
      ],
      "metadata": {
        "id": "5flkRaHo9VMT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_TOKEN=\"alexbg0897669616\""
      ],
      "metadata": {
        "id": "9EznsAzT9kiC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv('/content/drive/MyDrive/NovZhivot/.env')\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n"
      ],
      "metadata": {
        "id": "ymZWaTso963N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmTFS9PJiVsH"
      },
      "outputs": [],
      "source": [
        "# üå± –ü—Ä–æ–µ–∫—Ç ‚Äû–ù–æ–≤ –ñ–∏–≤–æ—Ç‚Äú\n",
        "\n",
        "# –ò–¥–µ—è: –î–∞ –≤–¥—ä—Ö–Ω–µ–º –∂–∏–≤–æ—Ç –Ω–∞ –∏–∑–æ—Å—Ç–∞–≤–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏ —á—Ä–µ–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ–Ω AI –ø—Ä–æ—Ü–µ—Å, —Å –ø–æ–º–æ—â—Ç–∞ –Ω–∞ Gemini, Colab –∏ GitHub. –í—Å–∏—á–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å–∞ –Ω–∞–ø—Ä–∞–≤–µ–Ω–∏ —Å —É–≤–∞–∂–µ–Ω–∏–µ, –∫–∞—Ç–æ fork –∏–ª–∏ pull request.\n",
        "\n",
        "# –¢–µ–∫—É—â –µ—Ç–∞–ø: –¢–µ—Å—Ç–≤–∞–Ω–µ –≤—ä—Ä—Ö—É –ª–∏—á–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏\n",
        "# –ê–≤—Ç–æ—Ä: AlexKitipov\n",
        "# –¶–µ–ª: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ –≤—ä–∑—Å—Ç–∞–Ω–æ–≤—è–≤–∞–Ω–µ –Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –°—É–ø–µ—Ä, –ê–ª–µ–∫—Å–∞–Ω–¥–∞—Ä! –©–æ–º —â–µ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ —Ç–≤–æ–∏—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏ –∫–∞—Ç–æ –±–∞–∑–∞, –º–æ–∂–µ–º –¥–∞ –∑–∞–ø–æ—á–Ω–µ–º —Å —è—Å–µ–Ω –∏ –µ—Ç–∏—á–µ–Ω —Å—Ç–∞—Ä—Ç. –ï—Ç–æ –∫–∞–∫ —â–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–º–µ –ø—ä—Ä–≤–∏—Ç–µ –µ—Ç–∞–ø–∏ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞ ‚Äû–ù–æ–≤ –ñ–∏–≤–æ—Ç‚Äú, —Å–≤—ä—Ä–∑–∞–Ω —Å —Ç–≤–æ—è GitHub –ø—Ä–æ—Ñ–∏–ª AlexKitipov:\n",
        "\n",
        "# ---\n",
        "\n",
        "# –ï—Ç–∞–ø 1: –ò–∑—Ç–µ–≥–ª—è–Ω–µ –Ω–∞ –ª–∏—á–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏ –æ—Ç GitHub\n",
        "\n",
        "# –ò–∑–ø–æ–ª–∑–≤–∞–º–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—Ç–æ finrl-test (https://github.com/AlexKitipov/finrl-test) –∫–∞—Ç–æ –ø—ä—Ä–≤–∏ —Ç–µ—Å—Ç–æ–≤ —Å–ª—É—á–∞–π\n",
        "# –ó–∞—Ä–µ–∂–¥–∞–º–µ –∫–æ–¥–∞ –≤ –Ω–æ–≤ Colab –±–µ–ª–µ–∂–Ω–∏–∫\n",
        "# –°—ä–∑–¥–∞–≤–∞–º–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑: –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ .py, .ipynb, README.md, LICENSE\n",
        "\n",
        "# ---\n",
        "\n",
        "# –ï—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å Gemini\n",
        "\n",
        "# –í—ä–≤ –≤—Å—è–∫–∞ –∫–ª–µ—Ç–∫–∞ –¥–æ–±–∞–≤—è–º–µ prompt –æ—Ç —Ç–∏–ø–∞:\n",
        "# ```python\n",
        "# # –ú–æ–ª—è, Gemini:\n",
        "# # –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥, –ø–æ–ø—Ä–∞–≤–∏ –≥—Ä–µ—à–∫–∏, –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏\n",
        "# ```\n",
        "# Gemini –≤—Ä—ä—â–∞ –ø–æ–¥–æ–±—Ä–µ–Ω –∫–æ–¥, –∫–æ–π—Ç–æ —Å–µ –∑–∞–ø–∏—Å–≤–∞ –∫–∞—Ç–æ –Ω–æ–≤–∞ –≤–µ—Ä—Å–∏—è\n",
        "# –î–æ–±–∞–≤—è–º–µ changelog –∏ –±–µ–ª–µ–∂–∫–∞ –∫–∞–∫–≤–æ –µ –ø—Ä–æ–º–µ–Ω–µ–Ω–æ\n",
        "\n",
        "# ---\n",
        "\n",
        "# –ï—Ç–∞–ø 3: –í—Ä—ä—â–∞–Ω–µ –∫—ä–º GitHub\n",
        "\n",
        "# –°—ä–∑–¥–∞–≤–∞–º–µ –Ω–æ–≤–æ —Ä–µ–ø–æ nov-jivot-lab –≤ —Ç–≤–æ—è –ø—Ä–æ—Ñ–∏–ª\n",
        "# –ö–∞—á–≤–∞–º–µ Colab –±–µ–ª–µ–∂–Ω–∏–∫–∞ + –ø–æ–¥–æ–±—Ä–µ–Ω–∏—Ç–µ –≤–µ—Ä—Å–∏–∏\n",
        "# –ê–∫–æ –∏–º–∞ –∑–Ω–∞—á–∏–º–∏ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è, —Å—ä–∑–¥–∞–≤–∞–º–µ fork –∏–ª–∏ pull request –∫—ä–º –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ—Ç–æ —Ä–µ–ø–æ\n",
        "# –í–∏–Ω–∞–≥–∏ –¥–æ–±–∞–≤—è–º–µ –±–µ–ª–µ–∂–∫–∞: ‚Äû–¢–æ–≤–∞ –µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ, –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è—Ç –∫–æ–¥ –µ –∑–∞–ø–∞–∑–µ–Ω‚Äú\n",
        "\n",
        "# ---\n",
        "\n",
        "# –ï—Ç–∞–ø 4: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ø—É–±–ª–∏—á–Ω–æ—Å—Ç\n",
        "\n",
        "# –°—ä–∑–¥–∞–≤–∞–º–µ README.md —Å –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞, –º–∏—Å–∏—è—Ç–∞ –∏ –µ—Ç–∞–ø–∏—Ç–µ\n",
        "# –î–æ–±–∞–≤—è–º–µ –µ—Ç–∏–∫–µ—Ç–∏: AI, Gemini, CodeRevival, PersonalLab\n",
        "# –í–∫–ª—é—á–≤–∞–º–µ –µ—Ç–∏—á–Ω–∞ —Ä–∞–º–∫–∞: ‚Äû–†–∞–±–æ—Ç–∏–º —Å–∞–º–æ —Å –æ—Ç–≤–æ—Ä–µ–Ω–∏ –ª–∏—Ü–µ–Ω–∑–∏ –∏ —Å —É–≤–∞–∂–µ–Ω–∏–µ –∫—ä–º –∞–≤—Ç–æ—Ä–∏—Ç–µ‚Äú\n",
        "\n",
        "# ---\n",
        "\n",
        "# –ê–∫–æ –∏—Å–∫–∞—à, –º–æ–≥–∞ –¥–∞ —Ç–∏ –ø–æ–¥–≥–æ—Ç–≤—è —Å—Ç–∞—Ä—Ç–æ–≤–∏—è Colab –±–µ–ª–µ–∂–Ω–∏–∫ —Å –≤—Å–∏—á–∫–æ —Ç–æ–≤–∞ ‚Äî –≥–æ—Ç–æ–≤ –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ. –°–∞–º–æ –º–∏ –∫–∞–∂–∏ –¥–∞–ª–∏ –∏—Å–∫–∞—à –∫–æ–º–µ–Ω—Ç–∞—Ä–∏—Ç–µ –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏—Ç–µ –≤—ä—Ç—Ä–µ –¥–∞ —Å–∞ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏, –∞–Ω–≥–ª–∏–π—Å–∫–∏ –∏–ª–∏ —Å–º–µ—Å–µ–Ω–æ. –î–∞ –∑–∞–ø–æ—á–Ω–µ–º?"
      ],
      "metadata": {
        "id": "XCNYU09bqO4a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üå± –ü—Ä–æ–µ–∫—Ç ‚Äû–ù–æ–≤ –ñ–∏–≤–æ—Ç‚Äú ‚Äî Colab Notebook Template\n",
        "\n",
        "# –¢–æ–∑–∏ —à–∞–±–ª–æ–Ω —Å–ª–µ–¥–≤–∞ –ø—Ä–µ–¥—Ö–æ–¥–Ω–∏—Ç–µ –µ—Ç–∞–ø–∏ –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ—Ç–æ –≤—ä–∑—Ä–∞–∂–¥–∞–Ω–µ –Ω–∞ –ª–∏—á–Ω–∏ —Ä–µ–ø–æ—Ç–∞.\n",
        "# –ö–æ–º–µ–Ω—Ç–∞—Ä–∏—Ç–µ —Å–∞ —Å–º–µ—Å–µ–Ω–æ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏.\n",
        "\n",
        "# ---\n",
        "\n",
        "## üìö –ï—Ç–∞–ø 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç–∏\n",
        "\n",
        "# ```python\n",
        "# –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–º–µ –Ω—É–∂–Ω–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ / install dependencies\n",
        "!pip install PyGithub gitpython\n",
        "\n",
        "# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–º–µ –æ—Å–Ω–æ–≤–Ω–∏ –º–æ–¥—É–ª–∏ / imports\n",
        "from github import Github\n",
        "from git import Repo\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è-–∑–∞–≥–æ—Ç–æ–≤–∫–∞ –∑–∞ –ø–æ–≤–∏–∫–≤–∞–Ω–µ –Ω–∞ Gemini\n",
        "def ask_gemini(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    –ú–æ–ª—è, Gemini:\n",
        "    Analyze, correct errors, suggest improvements and add comments.\n",
        "    Returns modified code as string.\n",
        "    \"\"\"\n",
        "    # TODO: –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Gemini API / integrate your API call here\n",
        "    # response = gemini_client.send(prompt)\n",
        "    # return response.text\n",
        "    return \"<modified code placeholder>\"\n",
        "\n",
        "# ```"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702XZKC3ryAH",
        "outputId": "c0f4655b-5058-4d9f-932d-06b921f22fcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.4.0)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (2025.7.14)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub) (1.17.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: Deprecated, pynacl, PyGithub\n",
            "Successfully installed Deprecated-1.2.18 PyGithub-2.6.1 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from github import Github\n",
        "from git import Repo\n",
        "import os, shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Your GitHub credentials and workspace\n",
        "GITHUB_TOKEN = \"ghp_XXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n"
      ],
      "metadata": {
        "id": "nkbWOO6kxutW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –§—É–Ω–∫—Ü–∏—è –∑–∞ —Å—ä–±–∏—Ä–∞–Ω–µ –Ω–∞ .py, .ipynb, README, LICENSE\n",
        "def collect_code_files(repo_path: str):\n",
        "    files = []\n",
        "    for root, dirs, filenames in os.walk(repo_path):\n",
        "        for fn in filenames:\n",
        "            if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                full = os.path.join(root, fn)\n",
        "                files.append(full)\n",
        "    return files\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä: —Å—ä–±–∏—Ä–∞–º–µ —Ñ–∞–π–ª–æ–≤–µ—Ç–µ –Ω–∞ –ø—ä—Ä–≤–æ—Ç–æ —Ä–µ–ø–æ\n",
        "# We need to ensure WORKDIR and REPOS are defined before using them here.\n",
        "# Assuming WORKDIR and REPOS are defined in a previous cell (like nkbWOO6kxutW).\n",
        "if 'WORKDIR' in locals() and 'REPOS' in locals() and REPOS:\n",
        "    first_repo_name = REPOS[0]\n",
        "    first_repo_path = os.path.join(WORKDIR, first_repo_name)\n",
        "\n",
        "    # Check if the repository directory exists before trying to collect files\n",
        "    if os.path.exists(first_repo_path):\n",
        "        code_files = collect_code_files(first_repo_path)\n",
        "        print(\"Files to analyze:\", code_files)\n",
        "    else:\n",
        "        print(f\"Repository directory not found: {first_repo_path}. Please ensure repositories are cloned first.\")\n",
        "else:\n",
        "    print(\"WORKDIR or REPOS variable not defined or REPOS list is empty. Please run previous cells to define them.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icUkTAnhsCNe",
        "outputId": "a17ca673-2efc-41b6-c4b6-b39bcb908d42"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository directory not found: /content/nov_jivot_lab/finrl-test. Please ensure repositories are cloned first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ó–∞ –≤—Å–µ–∫–∏ —Ñ–∞–π–ª –ø–æ–¥–∞–≤–∞–º–µ Gemini prompt\n",
        "for file_path in code_files:\n",
        "    print(f\"\\n--- Processing {file_path} ---\")\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        code_snippet = f.read()\n",
        "\n",
        "    # –°—ä–∑–¥–∞–≤–∞–º–µ prompt / build prompt\n",
        "    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ‚Äì –≥–µ–Ω–µ—Ä–∏—Ä–∞–π README.md —Å–µ–∫—Ü–∏—è.\n",
        "\n",
        "–ö–æ–¥:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "rEXq5o47sFzB",
        "outputId": "5104d5af-7933-4bd7-a4b2-316fc1033ed6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-36-2356360633.py, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-36-2356360633.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    prompt = f\"\"\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "\n",
        "## üîÑ –ï—Ç–∞–ø 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞ GitHub ‚Äî changelog –∏ push"
      ],
      "metadata": {
        "id": "MfT2zNlOsKbE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üå± –ü—Ä–æ–µ–∫—Ç ‚Äû–ù–æ–≤ –ñ–∏–≤–æ—Ç‚Äú\n",
        "\n",
        "# –ò–¥–µ—è: –í—ä–∑—Ä–∞–∂–¥–∞–Ω–µ –Ω–∞ –∏–∑–æ—Å—Ç–∞–≤–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏ —á—Ä–µ–∑ AI (Gemini + Colab).\n",
        "# –ê–≤—Ç–æ—Ä: AlexKitipov\n",
        "# –ï—Ç–∞–ø–∏:\n",
        "# 1. –ò–∑—Ç–µ–≥–ª—è–Ω–µ –Ω–∞ –ª–∏—á–Ω–∏ —Ä–µ–ø–æ—Ç–∞\n",
        "# 2. –ê–Ω–∞–ª–∏–∑ –∏ –ø–æ–ø—Ä–∞–≤–∫–∞ —Å Gemini\n",
        "# 3. –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤—ä–≤ `nov-jivot-lab`\n",
        "# 4. Fork/PR –∫—ä–º –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—Ç–µ —Ä–µ–ø–æ—Ç–∞ (–ø–æ –∂–µ–ª–∞–Ω–∏–µ)\n",
        "\n",
        "# –ï—Ç–∏—á–Ω–∞ —Ä–∞–º–∫–∞: —Ä–∞–±–æ—Ç–∏–º —Å–∞–º–æ —Å –ª–∏—á–Ω–∏ –∏ –æ—Ç–≤–æ—Ä–µ–Ω–∏ –ª–∏—Ü–µ–Ω–∑–∏—Ä–∞–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∏, –ø—Ä–µ–¥–ª–∞–≥–∞–º–µ –ø—Ä–æ–º–µ–Ω–∏ –∫–∞—Ç–æ fork/PR."
      ],
      "metadata": {
        "id": "Aijb916msOsK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìí ‚Äû–ù–æ–≤ –ñ–∏–≤–æ—Ç‚Äú ‚Äî –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ç–µ–Ω –º–æ–¥–µ–ª\n",
        "\n",
        "# –¢—É–∫ –æ–ø–∏—Å–≤–∞–º–µ —Å–ª–µ–¥–≤–∞—â–∏—Ç–µ —Å—Ç—ä–ø–∫–∏, –∫–æ–∏—Ç–æ —â–µ –≤–∫–∞—Ä–∞—Ç–µ –¥–∏—Ä–µ–∫—Ç–Ω–æ –≤ —Å–≤–æ—è Colab –±–µ–ª–µ–∂–Ω–∏–∫.\n",
        "# –ö–æ–º–µ–Ω—Ç–∞—Ä–∏—Ç–µ —Å–∞ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏.\n",
        "\n",
        "# ---\n",
        "\n",
        "## 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ä–µ–¥–∞—Ç–∞ / Environment Check\n",
        "\n",
        "# - –£–≤–µ—Ä–µ—Ç–µ —Å–µ, —á–µ –∏–∑–ø–æ–ª–∑–≤–∞—Ç–µ **Python 3.8+** –≤ Colab (Runtime ‚Üí Change runtime type).\n",
        "# - –°–≤–æ–±–æ–¥–Ω–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏ –ø–∞–º–µ—Ç: GPU/TPU –ø–æ –∏–∑–±–æ—Ä.\n",
        "\n",
        "# ---\n",
        "\n",
        "## 1. –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω–µ –Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ / Install Dependencies\n",
        "\n",
        "# ```python\n",
        "# üõ†Ô∏è Install core libraries\n",
        "!pip install PyGithub gitpython requests matplotlib pygments\n",
        "\n",
        "# ```"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh7IFPWmwK8l",
        "outputId": "1c8c1f23-1994-4b0f-8e5e-982c68d13ab8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyGithub in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (2.19.2)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (1.5.0)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.4.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from PyGithub) (1.2.18)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub) (1.17.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from github import Github\n",
        "from git import Repo\n",
        "import os, shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Your GitHub credentials and workspace\n",
        "GITHUB_TOKEN = userdata.get('GITHUB_TOKEN') # Get token from Colab Secrets\n",
        "if not GITHUB_TOKEN:\n",
        "    print(\"Warning: GITHUB_TOKEN not found in Colab Secrets. Please add it via the key icon on the left sidebar.\")\n",
        "\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "8b11c2Z6wPIL",
        "outputId": "503a027d-5760-492f-9c54-33661195386c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TimeoutException",
          "evalue": "Requesting secret GITHUB_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-47-1313622277.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Your GitHub credentials and workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mGITHUB_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GITHUB_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get token from Colab Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mGITHUB_TOKEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning: GITHUB_TOKEN not found in Colab Secrets. Please add it via the key icon on the left sidebar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutException\u001b[0m: Requesting secret GITHUB_TOKEN timed out. Secrets can only be fetched when running from the Colab UI."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "            raise ValueError(\"GitHub token is not provided or is invalid.\") # Added check for token\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user)\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed = []\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{GITHUB_USER}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            print(f\"Cloning {name} ‚Üí {dest}\")\n",
        "            Repo.clone_from(url, dest)\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        –ú–æ–ª—è, Gemini:\n",
        "        - Analyze and correct errors\n",
        "        - Suggest optimizations & add comments\n",
        "        - Generate missing documentation\n",
        "        \"\"\"\n",
        "        # TODO: integrate your Gemini API call here\n",
        "        # response = gemini_client.send(snippet)\n",
        "        # return response.text\n",
        "        return \"<modified code placeholder>\"\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        for repo in self.repos:\n",
        "            base = os.path.join(self.workdir, repo)\n",
        "            files = self.collect_files(base)\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                    snippet = f.read()\n",
        "\n",
        "                prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏ –≤ —Ç–æ–∑–∏ –∫–æ–¥.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "\n",
        "–ö–æ–¥:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "5wFcmJQ6wS4R",
        "outputId": "291ef53d-458d-4076-93e2-a84874b39c56"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-49-2685644658.py, line 57)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-49-2685644658.py\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    prompt = f\"\"\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "    model.setup_workspace()\n",
        "    model.clone_repos()\n",
        "    model.revive_code()\n",
        "    model.validate()\n",
        "    model.visualize()\n",
        "    model.commit_push()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7CcijN-DwYeh",
        "outputId": "557cfcc2-95f9-492b-f16a-f6214b858c67"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadCredentialsException",
          "evalue": "401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadCredentialsException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-48-997476967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNovZhivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGITHUB_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGITHUB_USER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORKDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREPOS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_workspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_repos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrevive_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-44-3082049357.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, token, user, workdir, repos)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Initialize GitHub client and workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mGithub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkdir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mworkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepos\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/MainClass.py\u001b[0m in \u001b[0;36mget_user\u001b[0;34m(self, login)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# always return a completed NamedUser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# v3: remove complete() here and make this as lazy as github.Github is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedUser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__requester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_user_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNamedUser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, requester, headers, attributes, completed, url, accept)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# neither of complete, headers and attributes are given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_not_lazy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_given\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_completeIfNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m_completeIfNeeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completeIfNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m__complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompletableObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cannot complete object as it contains no URL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequestJsonAndCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completeHeaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storeAndUseAttributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/Requester.py\u001b[0m in \u001b[0;36mrequestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input, follow_302_redirect)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[0;32m--> 624\u001b[0;31m         return self.__check(\n\u001b[0m\u001b[1;32m    625\u001b[0m             *self.requestJson(\n\u001b[1;32m    626\u001b[0m                 \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/Requester.py\u001b[0m in \u001b[0;36m__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__structuredFromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadCredentialsException\u001b[0m: 401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67594f6",
        "outputId": "dad4505a-6b00-437d-b978-4d26c7e530b7"
      },
      "source": [
        "!pip install python-dotenv"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6982d05b"
      },
      "source": [
        "# Task\n",
        "Explain the selected code, check for errors, correct the code, modify and extend it if necessary, and provide suggestions for further development of the project, incorporating the plan to integrate the Gemini API, analyze code from your repositories, generate improvement suggestions, automate fork/branch creation in your \"nov-jivot-lab\" repository, optionally generate a pull request, generate documentation and reports, and finalize and test the entire process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf107243"
      },
      "source": [
        "## –ü—Ä–µ–≥–ª–µ–¥ –∏ —É—Ç–æ—á–Ω—è–≤–∞–Ω–µ –Ω–∞ –∫–æ–¥–∞\n",
        "\n",
        "### Subtask:\n",
        "–©–µ –ø—Ä–µ–≥–ª–µ–¥–∞–º —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—â–∏—è –∫–æ–¥ –≤ –±–µ–ª–µ–∂–Ω–∏–∫–∞, —â–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–∞–º –∏ –∫–æ—Ä–∏–≥–∏—Ä–∞–º –≤—Å–∏—á–∫–∏ –æ—Å—Ç–∞–Ω–∞–ª–∏ –≥—Ä–µ—à–∫–∏ –∏ —â–µ –ø—Ä–µ–¥–ª–æ–∂–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏ –ø—Ä–æ–º–µ–Ω–∏ –∑–∞ –ø–æ-–¥–æ–±—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ba0a13"
      },
      "source": [
        "**Reasoning**:\n",
        "Reviewing the existing code cells, I see a few issues: multiple definitions of `GITHUB_TOKEN`, some commented-out code related to GitHub push that needs to be addressed for the full workflow, and the `ask_gemini` function is a placeholder. The class `NovZhivot` is a good step towards structuring the code, but it can be further refined. I will consolidate the token handling, fix the commented-out code, and prepare the structure for Gemini integration and GitHub interaction. I will also add comments for clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d0e210",
        "outputId": "1c2b3724-46f7-4dc3-d89d-5f7cab17874e"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from github import Github\n",
        "from git import Repo\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import py_compile\n",
        "\n",
        "# Consolidate GitHub token handling\n",
        "# It's best to load from environment variables or a secure method, but for this\n",
        "# notebook, we'll use a placeholder and note where to integrate secure loading.\n",
        "# GITHUB_TOKEN = os.getenv('GITHUB_TOKEN') # Preferred method in a real scenario\n",
        "GITHUB_TOKEN = \"YOUR_GITHUB_TOKEN\" # Replace with your actual token or load securely\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user)\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        –ú–æ–ª—è, Gemini:\n",
        "        - Analyze and correct errors\n",
        "        - Suggest optimizations & add comments\n",
        "        - Generate missing documentation\n",
        "        \"\"\"\n",
        "        # TODO: integrate your Gemini API call here\n",
        "        # This is a placeholder. Replace with actual API call.\n",
        "        print(\"Calling Gemini API (placeholder)...\")\n",
        "        # response = gemini_client.send(snippet)\n",
        "        # return response.text\n",
        "        return f\"# Revived by Nov Zhivot\\n{snippet}\\n# Improvements and comments from Gemini will be here.\"\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏ –≤ —Ç–æ–∑–∏ –∫–æ–¥.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "\n",
        "–ö–æ–¥:\n",
        "```python\n",
        "{snippet}\n",
        "```\"\"\"\n",
        "\n",
        "                    updated = self.ask_gemini(prompt)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                repo.remote(remote_name).set_url(f\"https://{self.user.login}:{GITHUB_TOKEN}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure GITHUB_TOKEN is set before initializing the class\n",
        "    if GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\":\n",
        "        print(\"Please replace 'YOUR_GITHUB_TOKEN' with your actual GitHub token.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please replace 'YOUR_GITHUB_TOKEN' with your actual GitHub token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d96ea6a"
      },
      "source": [
        "## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ gemini api\n",
        "\n",
        "### Subtask:\n",
        "–©–µ –∑–∞–º–µ–Ω–∏–º —Ç–µ–∫—É—â–∞—Ç–∞ placeholder —Ñ—É–Ω–∫—Ü–∏—è `ask_gemini` —Å —Ä–µ–∞–ª–Ω–æ –ø–æ–≤–∏–∫–≤–∞–Ω–µ –∫—ä–º Gemini API, –∑–∞ –¥–∞ –º–æ–∂–µ –º–æ–¥–µ–ª—ä—Ç –¥–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞ –∏ –ø–æ–¥–æ–±—Ä—è–≤–∞ –∫–æ–¥–∞ –æ—Ç —Ç–≤–æ–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—Ç–∞.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3371cc1"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary library for interacting with the Gemini API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "379b5ba0",
        "outputId": "ad279a89-c1f2-444c-c7dc-895906e2e66c"
      },
      "source": [
        "!pip install google-generativeai"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432d89f6"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the google.generativeai library and configure it with the API key. Then, modify the `ask_gemini` function to use the configured model to generate text based on the provided code snippet. Include basic error handling for the API call.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2c8362f",
        "outputId": "79ca2e3b-cce3-46a9-c90f-25d462374071"
      },
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# It's assumed the Gemini API key is stored as an environment variable or loaded securely.\n",
        "# Replace with your actual method of loading the API key.\n",
        "# For demonstration, using a placeholder and noting the requirement.\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY') # Load from environment or secure storage\n",
        "\n",
        "# Configure the generative AI model\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    # Choose a model, e.g., 'gemini-pro' or 'gemini-1.5-flash-latest'\n",
        "    # List available models: for m in genai.list_models(): print(m.name)\n",
        "    try:\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Gemini model configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Gemini model: {e}\")\n",
        "        gemini_model = None # Set to None if configuration fails\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY not found. Gemini API calls will be skipped.\")\n",
        "    gemini_model = None\n",
        "\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user)\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends code snippet to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            snippet: The code snippet string to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + snippet\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(snippet)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + snippet\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # No longer need to format the prompt explicitly here,\n",
        "                    # as the ask_gemini function handles sending the snippet.\n",
        "                    updated = self.ask_gemini(snippet)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                repo.remote(remote_name).set_url(f\"https://{self.user.login}:{GITHUB_TOKEN}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure GITHUB_TOKEN is set before initializing the class\n",
        "    if GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\":\n",
        "        print(\"Please replace 'YOUR_GITHUB_TOKEN' with your actual GitHub token.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "        print(\"Please set the GEMINI_API_KEY environment variable or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY not found. Gemini API calls will be skipped.\n",
            "Please replace 'YOUR_GITHUB_TOKEN' with your actual GitHub token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e8302ef"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the previous execution indicated that the `GEMINI_API_KEY` and `GITHUB_TOKEN` were not found or were still placeholders, the subtask requires ensuring these keys are loaded correctly. The user's request specifically mentions using an `.env` file or environment variable for the Gemini API key. I will update the code to explicitly load the `GEMINI_API_KEY` using `dotenv` and ensure the `GITHUB_TOKEN` is also correctly handled, although the primary focus remains on the Gemini integration. I will then run the main execution block again to test the updated loading and API configuration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b16a2899",
        "outputId": "23809ce8-b4fb-4f16-8fb2-bb048f713df0"
      },
      "source": [
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import shutil\n",
        "from github import Github\n",
        "from git import Repo\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import py_compile\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load API keys and configuration from environment variables\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "\n",
        "# Configure the generative AI model\n",
        "gemini_model = None # Initialize to None\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        # Choose a model, e.g., 'gemini-pro' or 'gemini-1.5-flash-latest'\n",
        "        # List available models: for m in genai.list_models(): print(m.name)\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Gemini model configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Gemini model: {e}\")\n",
        "        gemini_model = None # Ensure it's None if configuration fails\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY not found. Gemini API calls will be skipped.\")\n",
        "\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "             raise ValueError(\"GitHub token is not provided.\")\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user)\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends code snippet to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            snippet: The code snippet string to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + snippet\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(snippet)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + snippet\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # No longer need to format the prompt explicitly here,\n",
        "                    # as the ask_gemini function handles sending the snippet.\n",
        "                    updated = self.ask_gemini(snippet)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                repo.remote(remote_name).set_url(f\"https://{self.user.login}:{GITHUB_TOKEN}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    if not GITHUB_TOKEN:\n",
        "        print(\"GITHUB_TOKEN not found. Please set the GITHUB_TOKEN environment variable or update the code to load it securely.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "         print(\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY not found. Gemini API calls will be skipped.\n",
            "GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable or update the code to load it securely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7a262d5"
      },
      "source": [
        "## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ gemini api\n",
        "\n",
        "### Subtask:\n",
        "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–∞ gemini api (Retry 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dd92073"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to create a `.env` file in the Colab environment's root directory and add the `GEMINI_API_KEY` to it as instructed to ensure the key is available for the `load_dotenv()` function in the next step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4517a05",
        "outputId": "c4a1c9b9-c304-4c67-af96-ec64a48e0a60"
      },
      "source": [
        "# Create a .env file in the root directory and add the GEMINI_API_KEY\n",
        "env_file_path = '/content/.env'\n",
        "with open(env_file_path, 'w') as f:\n",
        "    f.write(\"GEMINI_API_KEY='your_gemini_api_key_here'\\n\") # Replace with your actual key\n",
        "\n",
        "print(f\".env file created at {env_file_path} with placeholder key.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".env file created at /content/.env with placeholder key.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "845109ff"
      },
      "source": [
        "**Reasoning**:\n",
        "The `.env` file has been created. Now I need to modify the code to explicitly load the `.env` file using `load_dotenv()`, verify that the `GEMINI_API_KEY` environment variable is correctly loaded, and ensure the `genai.configure()` call is executed only if the `GEMINI_API_KEY` is successfully loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "d045b3bc",
        "outputId": "62191283-a76e-4165-baf7-1212a3ae44de"
      },
      "source": [
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import shutil\n",
        "from github import Github\n",
        "from git import Repo\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import py_compile\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load API keys and configuration from environment variables\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "\n",
        "# Verify GEMINI_API_KEY is loaded\n",
        "print(f\"GEMINI_API_KEY loaded: {bool(os.getenv('GEMINI_API_KEY'))}\")\n",
        "\n",
        "# Configure the generative AI model\n",
        "gemini_model = None # Initialize to None\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        # Choose a model, e.g., 'gemini-pro' or 'gemini-1.5-flash-latest'\n",
        "        # List available models: for m in genai.list_models(): print(m.name)\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Gemini model configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Gemini model: {e}\")\n",
        "        gemini_model = None # Ensure it's None if configuration fails\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY not found. Gemini API calls will be skipped.\")\n",
        "\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "             raise ValueError(\"GitHub token is not provided.\")\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user)\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends code snippet to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            snippet: The code snippet string to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + snippet\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(snippet)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + snippet\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # No longer need to format the prompt explicitly here,\n",
        "                    # as the ask_gemini function handles sending the snippet.\n",
        "                    updated = self.ask_gemini(snippet)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure GITHUB_TOKEN is not None before using it\n",
        "                if self.github.access_token: # Use the token from the authenticated Github object\n",
        "                     repo.remote(remote_name).set_url(f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "                else:\n",
        "                     print(\"GitHub token not available for setting remote URL.\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    if not GITHUB_TOKEN:\n",
        "        print(\"GITHUB_TOKEN not found. Please set the GITHUB_TOKEN environment variable or update the code to load it securely.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "         print(\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY loaded: True\n",
            "Gemini model configured successfully.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadCredentialsException",
          "evalue": "401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadCredentialsException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-50-2303733475.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m          \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable or update the code to load it securely.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNovZhivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGITHUB_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGITHUB_USER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWORKDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREPOS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_workspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_repos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-50-2303733475.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, token, user, workdir, repos)\u001b[0m\n\u001b[1;32m     45\u001b[0m              \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GitHub token is not provided.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mGithub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkdir\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mworkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepos\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/MainClass.py\u001b[0m in \u001b[0;36mget_user\u001b[0;34m(self, login)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# always return a completed NamedUser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# v3: remove complete() here and make this as lazy as github.Github is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedUser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__requester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_user_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNamedUser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, requester, headers, attributes, completed, url, accept)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# neither of complete, headers and attributes are given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_not_lazy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_given\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_completeIfNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m_completeIfNeeded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_completeIfNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/GithubObject.py\u001b[0m in \u001b[0;36m__complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompletableObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cannot complete object as it contains no URL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequestJsonAndCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completeHeaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storeAndUseAttributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/Requester.py\u001b[0m in \u001b[0;36mrequestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input, follow_302_redirect)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[0;32m--> 624\u001b[0;31m         return self.__check(\n\u001b[0m\u001b[1;32m    625\u001b[0m             *self.requestJson(\n\u001b[1;32m    626\u001b[0m                 \u001b[0mverb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/github/Requester.py\u001b[0m in \u001b[0;36m__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__structuredFromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponseHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadCredentialsException\u001b[0m: 401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7fe9298"
      },
      "source": [
        "**Reasoning**:\n",
        "The `GEMINI_API_KEY` was successfully loaded, but there was a `BadCredentialsException` from GitHub. This indicates an issue with the `GITHUB_TOKEN`. Although the subtask is about integrating the Gemini API, the code execution failed before reaching the Gemini API call due to the GitHub authentication error. I need to ensure the `GITHUB_TOKEN` is correctly loaded as well. I will add a print statement to check if the `GITHUB_TOKEN` is loaded and remind the user to replace the placeholder if necessary. The Gemini API integration part seems correctly set up to proceed once the GitHub issue is resolved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUlGU69wCL8_",
        "outputId": "2e00da2f-e6c1-4c85-f099-f9a1ab0c943a"
      },
      "source": [
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import shutil\n",
        "from github import Github\n",
        "from git import Repo\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import py_compile\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load API keys and configuration from environment variables\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "\n",
        "# Verify API keys are loaded\n",
        "print(f\"GITHUB_TOKEN loaded: {bool(GITHUB_TOKEN)}\")\n",
        "if GITHUB_TOKEN and (GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\" or GITHUB_TOKEN == \"your_github_token_here\"):\n",
        "    print(\"Warning: GITHUB_TOKEN appears to be a placeholder. Please replace it with your actual token.\")\n",
        "print(f\"GEMINI_API_KEY loaded: {bool(GEMINI_API_KEY)}\")\n",
        "if GEMINI_API_KEY and (GEMINI_API_KEY == \"YOUR_GEMINI_API_KEY\" or GEMINI_API_KEY == \"your_gemini_api_key_here\"):\n",
        "     print(\"Warning: GEMINI_API_KEY appears to be a placeholder. Please replace it with your actual token.\")\n",
        "\n",
        "\n",
        "# Configure the generative AI model\n",
        "gemini_model = None # Initialize to None\n",
        "if GEMINI_API_KEY and GEMINI_API_KEY != \"your_gemini_api_key_here\": # Only configure if key is likely valid\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        # Choose a model, e.g., 'gemini-pro' or 'gemini-1.5-flash-latest'\n",
        "        # List available models: for m in genai.list_models(): print(m.name)\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Gemini model configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Gemini model: {e}\")\n",
        "        gemini_model = None # Ensure it's None if configuration fails\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY not found or is a placeholder. Gemini API calls will be skipped.\")\n",
        "\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token or token == \"YOUR_GITHUB_TOKEN\" or token == \"your_github_token_here\":\n",
        "             raise ValueError(\"GitHub token is not provided or is a placeholder. Please set a valid token.\")\n",
        "        self.github   = Github(token)\n",
        "        self.user     = self.github.get_user(user) # This is where the BadCredentialsException occurred\n",
        "\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends code snippet to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            snippet: The code snippet string to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + snippet\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(snippet)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + snippet\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # No longer need to format the prompt explicitly here,\n",
        "                    # as the ask_gemini function handles sending the snippet.\n",
        "                    updated = self.ask_gemini(snippet)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure GITHUB_TOKEN is not None before using it\n",
        "                if self.github.access_token: # Use the token from the authenticated Github object\n",
        "                     repo.remote(remote_name).set_url(f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "                else:\n",
        "                     print(\"GitHub token not available for setting remote URL.\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    if not GITHUB_TOKEN or GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\" or GITHUB_TOKEN == \"your_github_token_here\":\n",
        "        print(\"GITHUB_TOKEN not found or is a placeholder. Please set the GITHUB_TOKEN environment variable in the .env file or update the code to load it securely.\")\n",
        "    elif not GEMINI_API_KEY or GEMINI_API_KEY == \"your_gemini_api_key_here\":\n",
        "         print(\"GEMINI_API_KEY not found or is a placeholder. Please set the GEMINI_API_KEY environment variable in the .env file or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GITHUB_TOKEN loaded: True\n",
            "GEMINI_API_KEY loaded: True\n",
            "Warning: GEMINI_API_KEY appears to be a placeholder. Please replace it with your actual token.\n",
            "GEMINI_API_KEY not found or is a placeholder. Gemini API calls will be skipped.\n",
            "GEMINI_API_KEY not found or is a placeholder. Please set the GEMINI_API_KEY environment variable in the .env file or update the code to load it securely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d68fddd"
      },
      "source": [
        "## –†–∞–∑—à–∏—Ä—è–≤–∞–Ω–µ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç—Ç–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑\n",
        "\n",
        "### Subtask:\n",
        "–©–µ –¥–æ—Ä–∞–∑–≤–∏–µ–º —á–∞—Å—Ç—Ç–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑, —Ç–∞–∫–∞ —á–µ –¥–∞ —Å–µ –∏–∑–≤–ª–∏—á–∞ –ø–æ–≤–µ—á–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –∫–æ–¥–æ–≤–∏—Ç–µ —Ñ–∞–π–ª–æ–≤–µ (–Ω–∞–ø—Ä. –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –æ—Å–Ω–æ–≤–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad14ea8d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to modify the `NovZhivot` class to include a method for analyzing code details and then integrate this analysis into the `revive_code` method and the prompt sent to Gemini. I will start by implementing the `analyze_code_details` method using the `ast` module for Python files and simple string searching for other file types. Then, I will update `revive_code` to call this new method and include the analysis in the prompt for Gemini.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9b2e3d99",
        "outputId": "8a75d12c-3663-475a-cee1-42a8aae81853"
      },
      "source": [
        "import ast\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "             raise ValueError(\"GitHub token is not provided.\")\n",
        "        # Check if the token is the placeholder\n",
        "        if token == \"YOUR_GITHUB_TOKEN\":\n",
        "             print(\"Warning: Using placeholder GITHUB_TOKEN. Replace with your actual token for GitHub operations.\")\n",
        "        self.github   = Github(token)\n",
        "        try:\n",
        "            self.user = self.github.get_user(user)\n",
        "        except Exception as e:\n",
        "             print(f\"Error authenticating with GitHub: {e}\")\n",
        "             self.user = None # Set user to None if authentication fails\n",
        "\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        if self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping cloning.\")\n",
        "            return\n",
        "\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def analyze_code_details(self, file_path: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a code file to extract details like imports, functions, and documentation.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing extracted information.\n",
        "        \"\"\"\n",
        "        analysis_results = {\n",
        "            \"file_path\": file_path,\n",
        "            \"file_type\": os.path.splitext(file_path)[1],\n",
        "            \"imports\": [],\n",
        "            \"functions_classes\": [],\n",
        "            \"documentation\": [],\n",
        "            \"analysis_error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            analysis_results[\"content_preview\"] = content[:500] + \"...\" if len(content) > 500 else content\n",
        "\n",
        "            if file_path.endswith(\".py\"):\n",
        "                try:\n",
        "                    tree = ast.parse(content)\n",
        "                    for node in ast.walk(tree):\n",
        "                        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
        "                            for alias in (node.names if isinstance(node, ast.Import) else node.names):\n",
        "                                analysis_results[\"imports\"].append(alias.name)\n",
        "                        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
        "                            analysis_results[\"functions_classes\"].append(f\"{node.__class__.__name__}: {node.name}\")\n",
        "                            # Extract docstrings\n",
        "                            if ast.get_docstring(node):\n",
        "                                analysis_results[\"documentation\"].append(f\"{node.name} docstring: {ast.get_docstring(node)[:200]}...\") # Limit docstring preview\n",
        "                except SyntaxError as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Syntax error during AST parsing: {e}\"\n",
        "                except Exception as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Error during Python AST analysis: {e}\"\n",
        "            elif file_path.endswith(\".ipynb\"):\n",
        "                # Basic analysis for Jupyter notebooks (can be extended)\n",
        "                analysis_results[\"file_type\"] = \".ipynb\"\n",
        "                # Add logic to parse notebook structure and extract code cells\n",
        "                analysis_results[\"documentation\"].append(\"Jupyter Notebook analysis (basic)\")\n",
        "            elif file_path.endswith(\"README.md\"):\n",
        "                 analysis_results[\"file_type\"] = \"README.md\"\n",
        "                 analysis_results[\"documentation\"].append(f\"README content preview: {content[:500]}...\")\n",
        "            elif file_path.endswith(\"LICENSE\"):\n",
        "                 analysis_results[\"file_type\"] = \"LICENSE\"\n",
        "                 analysis_results[\"documentation\"].append(f\"LICENSE content preview: {content[:500]}...\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            analysis_results[\"analysis_error\"] = \"File not found.\"\n",
        "        except Exception as e:\n",
        "            analysis_results[\"analysis_error\"] = f\"Error reading or analyzing file: {e}\"\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "\n",
        "    def ask_gemini(self, snippet: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends a prompt to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt string including code snippet and analysis details.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + snippet\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(snippet)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + snippet\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, analyze, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        if self.user is None:\n",
        "             print(\"GitHub user not authenticated. Skipping code revival.\")\n",
        "             return\n",
        "\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    # Analyze the file\n",
        "                    analysis_data = self.analyze_code_details(fpath)\n",
        "                    print(\"Analysis results:\", analysis_data)\n",
        "\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # Include analysis data in the prompt for Gemini\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "- –ò–∑–ø–æ–ª–∑–≤–∞–π —Å–ª–µ–¥–Ω–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{analysis_data}\n",
        "\n",
        "–ö–æ–¥:"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-54-2088325552.py, line 172)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-54-2088325552.py\"\u001b[0;36m, line \u001b[0;32m172\u001b[0m\n\u001b[0;31m    prompt = f\"\"\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "901d190c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to a `SyntaxError: incomplete input`. This is because the f-string for the `prompt` variable was not closed properly. I need to fix the f-string syntax by adding the closing triple quotes. I will also add the closing triple quotes for the code snippet within the prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL7zjlTXCq5k",
        "outputId": "7c0ebf4d-3741-461f-9588-a4b9d51e0f7d"
      },
      "source": [
        "import ast\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "             raise ValueError(\"GitHub token is not provided.\")\n",
        "        # Check if the token is the placeholder\n",
        "        if token == \"YOUR_GITHUB_TOKEN\":\n",
        "             print(\"Warning: Using placeholder GITHUB_TOKEN. Replace with your actual token for GitHub operations.\")\n",
        "        self.github   = Github(token)\n",
        "        try:\n",
        "            self.user = self.github.get_user(user)\n",
        "        except Exception as e:\n",
        "             print(f\"Error authenticating with GitHub: {e}\")\n",
        "             self.user = None # Set user to None if authentication fails\n",
        "\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        if self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping cloning.\")\n",
        "            return\n",
        "\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def analyze_code_details(self, file_path: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a code file to extract details like imports, functions, and documentation.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing extracted information.\n",
        "        \"\"\"\n",
        "        analysis_results = {\n",
        "            \"file_path\": file_path,\n",
        "            \"file_type\": os.path.splitext(file_path)[1],\n",
        "            \"imports\": [],\n",
        "            \"functions_classes\": [],\n",
        "            \"documentation\": [],\n",
        "            \"analysis_error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            analysis_results[\"content_preview\"] = content[:500] + \"...\" if len(content) > 500 else content\n",
        "\n",
        "            if file_path.endswith(\".py\"):\n",
        "                try:\n",
        "                    tree = ast.parse(content)\n",
        "                    for node in ast.walk(tree):\n",
        "                        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
        "                            for alias in (node.names if isinstance(node, ast.Import) else node.names):\n",
        "                                analysis_results[\"imports\"].append(alias.name)\n",
        "                        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
        "                            analysis_results[\"functions_classes\"].append(f\"{node.__class__.__name__}: {node.name}\")\n",
        "                            # Extract docstrings\n",
        "                            if ast.get_docstring(node):\n",
        "                                analysis_results[\"documentation\"].append(f\"{node.name} docstring: {ast.get_docstring(node)[:200]}...\") # Limit docstring preview\n",
        "                except SyntaxError as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Syntax error during AST parsing: {e}\"\n",
        "                except Exception as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Error during Python AST analysis: {e}\"\n",
        "            elif file_path.endswith(\".ipynb\"):\n",
        "                # Basic analysis for Jupyter notebooks (can be extended)\n",
        "                analysis_results[\"file_type\"] = \".ipynb\"\n",
        "                # Add logic to parse notebook structure and extract code cells\n",
        "                analysis_results[\"documentation\"].append(\"Jupyter Notebook analysis (basic)\")\n",
        "            elif file_path.endswith(\"README.md\"):\n",
        "                 analysis_results[\"file_type\"] = \"README.md\"\n",
        "                 analysis_results[\"documentation\"].append(f\"README content preview: {content[:500]}...\")\n",
        "            elif file_path.endswith(\"LICENSE\"):\n",
        "                 analysis_results[\"file_type\"] = \"LICENSE\"\n",
        "                 analysis_results[\"documentation\"].append(f\"LICENSE content preview: {content[:500]}...\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            analysis_results[\"analysis_error\"] = \"File not found.\"\n",
        "        except Exception as e:\n",
        "            analysis_results[\"analysis_error\"] = f\"Error reading or analyzing file: {e}\"\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "\n",
        "    def ask_gemini(self, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends a prompt to Gemini API for analysis and improvement.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt string including code snippet and analysis details.\n",
        "\n",
        "        Returns:\n",
        "            A string containing the modified/improved code from Gemini,\n",
        "            or an error message if the API call fails or is skipped.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + prompt\n",
        "\n",
        "        print(\"Calling Gemini API...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + prompt\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, analyze, prompt, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        if self.user is None:\n",
        "             print(\"GitHub user not authenticated. Skipping code revival.\")\n",
        "             return\n",
        "\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    # Analyze the file\n",
        "                    analysis_data = self.analyze_code_details(fpath)\n",
        "                    print(\"Analysis results:\", analysis_data)\n",
        "\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # Include analysis data in the prompt for Gemini\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "- –ò–∑–ø–æ–ª–∑–≤–∞–π —Å–ª–µ–¥–Ω–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{analysis_data}\n",
        "\n",
        "–ö–æ–¥:\n",
        "```python\n",
        "{snippet}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "                    updated = self.ask_gemini(prompt)\n",
        "\n",
        "                    # Determine the output path. For now, append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated)\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed and saved to {out_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure GITHUB_TOKEN is not None before using it\n",
        "                if self.github.access_token: # Use the token from the authenticated Github object\n",
        "                     repo.remote(remote_name).set_url(f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "                else:\n",
        "                     print(\"GitHub token not available for setting remote URL.\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    if not GITHUB_TOKEN or GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\":\n",
        "        print(\"GITHUB_TOKEN not found or is a placeholder. Please set the GITHUB_TOKEN environment variable in the .env file or update the code to load it securely.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "         print(\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable in the .env file or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error authenticating with GitHub: 401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}\n",
            "Workspace setup at /content/nov_jivot_lab\n",
            "Cloning repositories...\n",
            "GitHub user not authenticated. Skipping cloning.\n",
            "Starting code revival process...\n",
            "GitHub user not authenticated. Skipping code revival.\n",
            "\n",
            "Validating processed files...\n",
            "\n",
            "Total files processed and revived: 0\n",
            "No files were processed to visualize.\n",
            "\n",
            "Preparing to commit and push...\n",
            "Initializing new repository at /content/nov_jivot_lab/nov-jivot-lab\n",
            "No changes to commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b041ea7f"
      },
      "source": [
        "## –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è\n",
        "\n",
        "### Subtask:\n",
        "–ù–∞ –±–∞–∑–∞—Ç–∞ –Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç Gemini, —â–µ –≥–µ–Ω–µ—Ä–∏—Ä–∞–º–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è, –∫–æ–∏—Ç–æ –º–æ–≥–∞—Ç –¥–∞ –≤–∫–ª—é—á–≤–∞—Ç –∫–æ—Ä–µ–∫—Ü–∏–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, –¥–æ–±–∞–≤—è–Ω–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏–ª–∏ –Ω–æ–≤–∏ —Ñ—É–Ω–∫—Ü–∏–∏.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b56bf536"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `ask_gemini` method to explicitly instruct Gemini to provide structured suggestions and update `revive_code` to process and store these suggestions alongside the processed files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fe748a6",
        "outputId": "b44484ca-c7a3-4169-a128-f7bd5949d8ee"
      },
      "source": [
        "import ast\n",
        "import json # Import json for potential structured output handling\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token:\n",
        "             raise ValueError(\"GitHub token is not provided.\")\n",
        "        # Check if the token is the placeholder\n",
        "        if token == \"YOUR_GITHUB_TOKEN\":\n",
        "             print(\"Warning: Using placeholder GITHUB_TOKEN. Replace with your actual token for GitHub operations.\")\n",
        "        self.github   = Github(token)\n",
        "        try:\n",
        "            self.user = self.github.get_user(user)\n",
        "        except Exception as e:\n",
        "             print(f\"Error authenticating with GitHub: {e}\")\n",
        "             self.user = None # Set user to None if authentication fails\n",
        "\n",
        "        self.workdir  = workdir\n",
        "        self.repos    = repos\n",
        "        self.processed_files = [] # Renamed for clarity\n",
        "        self.suggestions = {} # Dictionary to store suggestions per file\n",
        "        self.lab_repo_path = os.path.join(self.workdir, \"nov-jivot-lab\")\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        if self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping cloning.\")\n",
        "            return\n",
        "\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def analyze_code_details(self, file_path: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a code file to extract details like imports, functions, and documentation.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing extracted information.\n",
        "        \"\"\"\n",
        "        analysis_results = {\n",
        "            \"file_path\": file_path,\n",
        "            \"file_type\": os.path.splitext(file_path)[1],\n",
        "            \"imports\": [],\n",
        "            \"functions_classes\": [],\n",
        "            \"documentation\": [],\n",
        "            \"analysis_error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            analysis_results[\"content_preview\"] = content[:500] + \"...\" if len(content) > 500 else content\n",
        "\n",
        "            if file_path.endswith(\".py\"):\n",
        "                try:\n",
        "                    tree = ast.parse(content)\n",
        "                    for node in ast.walk(tree):\n",
        "                        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
        "                            for alias in (node.names if isinstance(node, ast.Import) else node.names):\n",
        "                                analysis_results[\"imports\"].append(alias.name)\n",
        "                        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
        "                            analysis_results[\"functions_classes\"].append(f\"{node.__class__.__name__}: {node.name}\")\n",
        "                            # Extract docstrings\n",
        "                            if ast.get_docstring(node):\n",
        "                                analysis_results[\"documentation\"].append(f\"{node.name} docstring: {ast.get_docstring(node)[:200]}...\") # Limit docstring preview\n",
        "                except SyntaxError as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Syntax error during AST parsing: {e}\"\n",
        "                except Exception as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Error during Python AST analysis: {e}\"\n",
        "            elif file_path.endswith(\".ipynb\"):\n",
        "                # Basic analysis for Jupyter notebooks (can be extended)\n",
        "                analysis_results[\"file_type\"] = \".ipynb\"\n",
        "                # Add logic to parse notebook structure and extract code cells\n",
        "                analysis_results[\"documentation\"].append(\"Jupyter Notebook analysis (basic)\")\n",
        "            elif file_path.endswith(\"README.md\"):\n",
        "                 analysis_results[\"file_type\"] = \"README.md\"\n",
        "                 analysis_results[\"documentation\"].append(f\"README content preview: {content[:500]}...\")\n",
        "            elif file_path.endswith(\"LICENSE\"):\n",
        "                 analysis_results[\"file_type\"] = \"LICENSE\"\n",
        "                 analysis_results[\"documentation\"].append(f\"LICENSE content preview: {content[:500]}...\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            analysis_results[\"analysis_error\"] = \"File not found.\"\n",
        "        except Exception as e:\n",
        "            analysis_results[\"analysis_error\"] = f\"Error reading or analyzing file: {e}\"\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "\n",
        "    def ask_gemini(self, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends a prompt to Gemini API for analysis and improvement.\n",
        "        Explicitly asks Gemini for structured suggestions.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt string including code snippet and analysis details.\n",
        "\n",
        "        Returns:\n",
        "            A string containing Gemini's response, which should include\n",
        "            the modified code and structured suggestions.\n",
        "        \"\"\"\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + prompt + \"\\n## Suggestions:\\n- Gemini API not available.\"\n",
        "\n",
        "        print(\"Calling Gemini API with detailed prompt...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + prompt + \"\\n## Suggestions:\\n- Error retrieving suggestions from Gemini.\"\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, analyze, prompt, process Gemini response, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        if self.user is None:\n",
        "             print(\"GitHub user not authenticated. Skipping code revival.\")\n",
        "             return\n",
        "\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    # Analyze the file\n",
        "                    analysis_data = self.analyze_code_details(fpath)\n",
        "                    print(\"Analysis results:\", analysis_data)\n",
        "\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # Include analysis data and specific instruction for structured suggestions\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "- –ò–∑–ø–æ–ª–∑–≤–∞–π —Å–ª–µ–¥–Ω–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{json.dumps(analysis_data, indent=2)}\n",
        "\n",
        "–ö–æ–¥:\n",
        "```python\n",
        "{snippet}\n",
        "```\n",
        "\n",
        "–í –∫—Ä–∞—è –Ω–∞ —Ç–≤–æ—è –æ—Ç–≥–æ–≤–æ—Ä, –º–æ–ª—è, –¥–æ–±–∞–≤–∏ —Å–µ–∫—Ü–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω –≤–∏–¥ (–Ω–∞–ø—Ä. —Å–ø–∏—Å—ä–∫ —Å —Ç–æ—á–∫–∏) –ø–æ–¥ –∑–∞–≥–ª–∞–≤–∏–µ \"## Suggestions:\".\n",
        "\"\"\"\n",
        "\n",
        "                    gemini_response = self.ask_gemini(prompt)\n",
        "\n",
        "                    # Process Gemini's response to extract suggestions and updated code\n",
        "                    updated_code = gemini_response\n",
        "                    suggestions_text = \"No suggestions found.\"\n",
        "\n",
        "                    # Simple approach to find the suggestions section\n",
        "                    suggestions_marker = \"## Suggestions:\"\n",
        "                    if suggestions_marker in gemini_response:\n",
        "                        parts = gemini_response.split(suggestions_marker, 1)\n",
        "                        updated_code = parts[0].strip()\n",
        "                        suggestions_text = suggestions_marker + parts[1].strip()\n",
        "                    else:\n",
        "                         print(\"Suggestions marker not found in Gemini response.\")\n",
        "\n",
        "\n",
        "                    # Store suggestions\n",
        "                    relative_path = os.path.relpath(fpath, self.workdir)\n",
        "                    self.suggestions[relative_path] = suggestions_text\n",
        "                    print(f\"Extracted suggestions for {relative_path}.\")\n",
        "\n",
        "                    # Determine the output path. Append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    # Save the updated code and suggestions\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated_code)\n",
        "                        out.write(\"\\n\\n\") # Add a separator\n",
        "                        out.write(suggestions_text) # Append suggestions to the file\n",
        "\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed, saved updated code and suggestions to {out_path}\")\n",
        "\n",
        "                    # Optionally, save suggestions to a separate file\n",
        "                    suggestions_out_path = f\"{name}_revived_suggestions.md\"\n",
        "                    with open(suggestions_out_path, \"w\", encoding=\"utf-8\") as out_sugg:\n",
        "                        out_sugg.write(suggestions_text)\n",
        "                    print(f\"Saved suggestions to {suggestions_out_path}\")\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        # Initialize a new local repo for the lab and commit\n",
        "        print(\"\\nPreparing to commit and push...\")\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "            # Add all processed files to the staging area\n",
        "            repo.git.add(A=True) # Use A=True to add new, modified, and deleted files\n",
        "\n",
        "            # Also add the separate suggestions files\n",
        "            for relative_path in self.suggestions.keys():\n",
        "                 # Construct the path to the suggestions file\n",
        "                 name, ext = os.path.splitext(os.path.join(self.workdir, relative_path))\n",
        "                 suggestions_out_path = f\"{name}_revived_suggestions.md\"\n",
        "                 if os.path.exists(suggestions_out_path):\n",
        "                      repo.git.add(suggestions_out_path)\n",
        "                      print(f\"Added suggestions file to staging: {suggestions_out_path}\")\n",
        "\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # Configure remote and push - This part requires a valid GitHub token with repo permissions\n",
        "                # and the 'nov-jivot-lab' repository to exist on GitHub under the user's account.\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/nov-jivot-lab.git\"\n",
        "\n",
        "                # Check if remote already exists\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure GITHUB_TOKEN is not None before using it\n",
        "                if self.github.access_token: # Use the token from the authenticated Github object\n",
        "                     repo.remote(remote_name).set_url(f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/nov-jivot-lab.git\")\n",
        "                else:\n",
        "                     print(\"GitHub token not available for setting remote URL.\")\n",
        "\n",
        "\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                try:\n",
        "                    origin.push(refspec='HEAD:refs/heads/main', force=True) # Use force push for simplicity in this lab, be cautious in real projects.\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error pushing to GitHub: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    if not GITHUB_TOKEN or GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\":\n",
        "        print(\"GITHUB_TOKEN not found or is a placeholder. Please set the GITHUB_TOKEN environment variable in the .env file or update the code to load it securely.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "         print(\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable in the .env file or update the code to load it securely.\")\n",
        "    else:\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "        model.setup_workspace()\n",
        "        model.clone_repos()\n",
        "        model.revive_code()\n",
        "        model.validate()\n",
        "        model.visualize()\n",
        "        model.commit_push()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error authenticating with GitHub: 401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}\n",
            "Workspace setup at /content/nov_jivot_lab\n",
            "Cloning repositories...\n",
            "GitHub user not authenticated. Skipping cloning.\n",
            "Starting code revival process...\n",
            "GitHub user not authenticated. Skipping code revival.\n",
            "\n",
            "Validating processed files...\n",
            "\n",
            "Total files processed and revived: 0\n",
            "No files were processed to visualize.\n",
            "\n",
            "Preparing to commit and push...\n",
            "Initializing new repository at /content/nov_jivot_lab/nov-jivot-lab\n",
            "No changes to commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b47e404"
      },
      "source": [
        "## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–∞–Ω–æ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ —Ñ–æ—Ä–∫/–∫–ª–æ–Ω\n",
        "\n",
        "### Subtask:\n",
        "–©–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–∞–º–µ —Å—Ç—ä–ø–∫–∞—Ç–∞ –∑–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ —Ñ–æ—Ä–∫ –∏–ª–∏ –Ω–æ–≤ –∫–ª–æ–Ω –≤ —Ç–≤–æ–µ—Ç–æ `nov-jivot-lab` —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏, –∫—ä–¥–µ—Ç–æ —â–µ –±—ä–¥–∞—Ç –∫–∞—á–µ–Ω–∏ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—Ç–µ —Ñ–∞–π–ª–æ–≤–µ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa4967c5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to modify the `commit_push` method to create the `nov-jivot-lab` repository on GitHub if it doesn't exist, configure the remote, and push the committed changes. This directly addresses instructions 1, 2, 3, and 4 of the current subtask. I will also add a print statement about token permissions as per instruction 6. I will not implement instruction 5 (branch creation logic) in this step but will note it as a potential improvement in the code comments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b32acc",
        "outputId": "08975ed1-b7d6-40cb-d801-183c5d3230a3"
      },
      "source": [
        "import ast\n",
        "import json\n",
        "from github import GithubException, UnknownObjectException # Import specific GitHub exceptions\n",
        "from git import Repo, GitCommandError # Import GitCommandError\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # Initialize GitHub client and workspace\n",
        "        if not token or token == \"YOUR_GITHUB_TOKEN\":\n",
        "             print(\"Error: GitHub token is not provided or is a placeholder. Please set a valid token.\")\n",
        "             self.github = None\n",
        "             self.user = None\n",
        "             self.authenticated = False\n",
        "             return\n",
        "\n",
        "        self.github = Github(token)\n",
        "        try:\n",
        "            self.user = self.github.get_user() # Get the authenticated user directly\n",
        "            print(f\"Authenticated as GitHub user: {self.user.login}\")\n",
        "            self.authenticated = True\n",
        "        except Exception as e:\n",
        "             print(f\"Error authenticating with GitHub: {e}\")\n",
        "             self.user = None # Set user to None if authentication fails\n",
        "             self.authenticated = False\n",
        "\n",
        "\n",
        "        self.workdir = workdir\n",
        "        self.repos = repos\n",
        "        self.processed_files = []\n",
        "        self.suggestions = {}\n",
        "        self.lab_repo_name = \"nov-jivot-lab\" # Define lab repo name\n",
        "        self.lab_repo_path = os.path.join(self.workdir, self.lab_repo_name)\n",
        "\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping cloning.\")\n",
        "            return\n",
        "\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except GitCommandError as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def analyze_code_details(self, file_path: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a code file to extract details like imports, functions, and documentation.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing extracted information.\n",
        "        \"\"\"\n",
        "        analysis_results = {\n",
        "            \"file_path\": file_path,\n",
        "            \"file_type\": os.path.splitext(file_path)[1],\n",
        "            \"imports\": [],\n",
        "            \"functions_classes\": [],\n",
        "            \"documentation\": [],\n",
        "            \"analysis_error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            analysis_results[\"content_preview\"] = content[:500] + \"...\" if len(content) > 500 else content\n",
        "\n",
        "            if file_path.endswith(\".py\"):\n",
        "                try:\n",
        "                    tree = ast.parse(content)\n",
        "                    for node in ast.walk(tree):\n",
        "                        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
        "                            for alias in (node.names if isinstance(node, ast.Import) else node.names):\n",
        "                                analysis_results[\"imports\"].append(alias.name)\n",
        "                        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
        "                            analysis_results[\"functions_classes\"].append(f\"{node.__class__.__name__}: {node.name}\")\n",
        "                            # Extract docstrings\n",
        "                            if ast.get_docstring(node):\n",
        "                                analysis_results[\"documentation\"].append(f\"{node.name} docstring: {ast.get_docstring(node)[:200]}...\") # Limit docstring preview\n",
        "                except SyntaxError as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Syntax error during AST parsing: {e}\"\n",
        "                except Exception as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Error during Python AST analysis: {e}\"\n",
        "            elif file_path.endswith(\".ipynb\"):\n",
        "                # Basic analysis for Jupyter notebooks (can be extended)\n",
        "                analysis_results[\"file_type\"] = \".ipynb\"\n",
        "                # Add logic to parse notebook structure and extract code cells\n",
        "                analysis_results[\"documentation\"].append(\"Jupyter Notebook analysis (basic)\")\n",
        "            elif file_path.endswith(\"README.md\"):\n",
        "                 analysis_results[\"file_type\"] = \"README.md\"\n",
        "                 analysis_results[\"documentation\"].append(f\"README content preview: {content[:500]}...\")\n",
        "            elif file_path.endswith(\"LICENSE\"):\n",
        "                 analysis_results[\"file_type\"] = \"LICENSE\"\n",
        "                 analysis_results[\"documentation\"].append(f\"LICENSE content preview: {content[:500]}...\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            analysis_results[\"analysis_error\"] = \"File not found.\"\n",
        "        except Exception as e:\n",
        "            analysis_results[\"analysis_error\"] = f\"Error reading or analyzing file: {e}\"\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "\n",
        "    def ask_gemini(self, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends a prompt to Gemini API for analysis and improvement.\n",
        "        Explicitly asks Gemini for structured suggestions.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt string including code snippet and analysis details.\n",
        "\n",
        "        Returns:\n",
        "            A string containing Gemini's response, which should include\n",
        "            the modified code and structured suggestions.\n",
        "        \"\"\"\n",
        "        # Access gemini_model from the global scope or pass it to the class init if preferred\n",
        "        global gemini_model\n",
        "\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + prompt + \"\\n## Suggestions:\\n- Gemini API not available.\"\n",
        "\n",
        "        print(\"Calling Gemini API with detailed prompt...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + prompt + \"\\n## Suggestions:\\n- Error retrieving suggestions from Gemini.\"\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, analyze, prompt, process Gemini response, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "             print(\"GitHub user not authenticated. Skipping code revival.\")\n",
        "             return\n",
        "\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    # Analyze the file\n",
        "                    analysis_data = self.analyze_code_details(fpath)\n",
        "                    print(\"Analysis results:\", json.dumps(analysis_data, indent=2)) # Print analysis data\n",
        "\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # Include analysis data and specific instruction for structured suggestions\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "- –ò–∑–ø–æ–ª–∑–≤–∞–π —Å–ª–µ–¥–Ω–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{json.dumps(analysis_data, indent=2)}\n",
        "\n",
        "–ö–æ–¥:\n",
        "```python\n",
        "{snippet}\n",
        "```\n",
        "\n",
        "–í –∫—Ä–∞—è –Ω–∞ —Ç–≤–æ—è –æ—Ç–≥–æ–≤–æ—Ä, –º–æ–ª—è, –¥–æ–±–∞–≤–∏ —Å–µ–∫—Ü–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω –≤–∏–¥ (–Ω–∞–ø—Ä. —Å–ø–∏—Å—ä–∫ —Å —Ç–æ—á–∫–∏) –ø–æ–¥ –∑–∞–≥–ª–∞–≤–∏–µ \"## Suggestions:\".\n",
        "\"\"\"\n",
        "\n",
        "                    gemini_response = self.ask_gemini(prompt)\n",
        "\n",
        "                    # Process Gemini's response to extract suggestions and updated code\n",
        "                    updated_code = gemini_response\n",
        "                    suggestions_text = \"No suggestions found.\"\n",
        "\n",
        "                    # Simple approach to find the suggestions section\n",
        "                    suggestions_marker = \"## Suggestions:\"\n",
        "                    if suggestions_marker in gemini_response:\n",
        "                        parts = gemini_response.split(suggestions_marker, 1)\n",
        "                        updated_code = parts[0].strip()\n",
        "                        suggestions_text = suggestions_marker + parts[1].strip()\n",
        "                    else:\n",
        "                         print(\"Suggestions marker not found in Gemini response.\")\n",
        "\n",
        "\n",
        "                    # Store suggestions\n",
        "                    relative_path = os.path.relpath(fpath, self.workdir)\n",
        "                    self.suggestions[relative_path] = suggestions_text\n",
        "                    print(f\"Extracted suggestions for {relative_path}.\")\n",
        "\n",
        "                    # Determine the output path. Append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    # Save the updated code and suggestions\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated_code)\n",
        "                        out.write(\"\\n\\n\") # Add a separator\n",
        "                        out.write(suggestions_text) # Append suggestions to the file\n",
        "\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed, saved updated code and suggestions to {out_path}\")\n",
        "\n",
        "                    # Optionally, save suggestions to a separate file\n",
        "                    suggestions_out_path = f\"{name}_revived_suggestions.md\"\n",
        "                    with open(suggestions_out_path, \"w\", encoding=\"utf-8\") as out_sugg:\n",
        "                        out_sugg.write(suggestions_text)\n",
        "                    print(f\"Saved suggestions to {suggestions_out_path}\")\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        print(\"\\nPreparing to commit and push to GitHub...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping commit and push.\")\n",
        "            return\n",
        "\n",
        "        # 1. Ensure the local repository exists and is initialized\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new local repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "\n",
        "            # Add all processed files and suggestion files to the staging area\n",
        "            repo.git.add(A=True)\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                print(\"Changes detected. Committing...\")\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # 2. Ensure the remote repository exists on GitHub\n",
        "                print(f\"Checking for remote repository '{self.lab_repo_name}' on GitHub...\")\n",
        "                try:\n",
        "                    remote_repo = self.user.get_repo(self.lab_repo_name)\n",
        "                    print(f\"Remote repository '{self.lab_repo_name}' found.\")\n",
        "                except UnknownObjectException:\n",
        "                    print(f\"Remote repository '{self.lab_repo_name}' not found. Creating it...\")\n",
        "                    try:\n",
        "                        remote_repo = self.user.create_repo(\n",
        "                            self.lab_repo_name,\n",
        "                            description=\"Revived code and suggestions from personal projects by Nov Zhivot AI.\",\n",
        "                            private=False # Set to True if you want a private repository\n",
        "                        )\n",
        "                        print(f\"Remote repository '{self.lab_repo_name}' created successfully.\")\n",
        "                        print(\"Please ensure your GitHub token has the 'public_repo' or 'repo' scope to create repositories.\")\n",
        "                    except GithubException as e:\n",
        "                        print(f\"Error creating remote repository '{self.lab_repo_name}': {e}\")\n",
        "                        print(\"Please ensure your GitHub token has the necessary permissions (e.g., 'public_repo' or 'repo') to create repositories.\")\n",
        "                        return # Stop if repo creation fails\n",
        "                except Exception as e:\n",
        "                    print(f\"An unexpected error occurred while checking/creating remote repository: {e}\")\n",
        "                    return\n",
        "\n",
        "\n",
        "                # 3. Configure the local repository's remote URL\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/{self.lab_repo_name}.git\"\n",
        "\n",
        "                # Check if remote already exists and update URL if necessary\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     if origin.url != remote_url:\n",
        "                         print(f\"Updating remote '{remote_name}' URL to: {remote_url}\")\n",
        "                         origin.set_url(remote_url)\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure the URL includes the token for authentication when pushing\n",
        "                auth_remote_url = f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/{self.lab_repo_name}.git\"\n",
        "                origin.set_url(auth_remote_url)\n",
        "                print(f\"Remote URL set for authentication.\")\n",
        "\n",
        "\n",
        "                # 4. Implement the logic to push changes\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                print(\"Please ensure your GitHub token has push permissions to the repository.\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                # Instruction 5 Note: Pushing to 'main' as per previous steps. Creating new branches per revival\n",
        "                # could be implemented here for better history management.\n",
        "                try:\n",
        "                    # Fetch before pushing to potentially avoid conflicts if the remote repo was just created\n",
        "                    # and GitHub added an initial commit (like README).\n",
        "                    try:\n",
        "                         origin.fetch()\n",
        "                         print(\"Fetched from remote.\")\n",
        "                    except GitCommandError as e:\n",
        "                         print(f\"Could not fetch from remote (might be a new empty repo): {e}\")\n",
        "\n",
        "\n",
        "                    # Push the current HEAD (latest commit) to the 'main' branch on the remote.\n",
        "                    # Use force=True for simplicity in this lab to overwrite potential initial commits\n",
        "                    # or diverging histories. Be very cautious with force=True in real projects.\n",
        "                    push_info = origin.push(refspec='HEAD:refs/heads/main', force=True)\n",
        "\n",
        "                    # Check push results for errors\n",
        "                    if push_info:\n",
        "                        for info in push_info:\n",
        "                            if info.summary.startswith('!'): # Indicates an error\n",
        "                                print(f\"Push failed: {info.summary}\")\n",
        "                                print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "                            else:\n",
        "                                print(f\"Successfully pushed: {info.summary}\")\n",
        "                    else:\n",
        "                        print(\"Push completed with no detailed info.\")\n",
        "\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except GitCommandError as e:\n",
        "                    print(f\"Error during git push: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"An unexpected error occurred during push: {e}\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push preparation: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY are set\n",
        "    # GITHUB_TOKEN and GEMINI_API_KEY are loaded via dotenv at the beginning of the script\n",
        "    if not GITHUB_TOKEN or GITHUB_TOKEN == \"YOUR_GITHUB_TOKEN\":\n",
        "        print(\"GITHUB_TOKEN not found or is a placeholder. Please set a valid GITHUB_TOKEN environment variable in the .env file.\")\n",
        "    elif not GEMINI_API_KEY:\n",
        "         print(\"GEMINI_API_KEY not found. Please set the GEMINI_API_KEY environment variable in the .env file.\")\n",
        "    else:\n",
        "        # Pass the loaded tokens to the class\n",
        "        model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "\n",
        "        # Only proceed if GitHub authentication was successful\n",
        "        if model.authenticated:\n",
        "             model.setup_workspace()\n",
        "             model.clone_repos()\n",
        "             # If gemini_model is None, model.revive_code() will skip Gemini calls\n",
        "             model.revive_code()\n",
        "             model.validate()\n",
        "             model.visualize()\n",
        "             model.commit_push()\n",
        "        else:\n",
        "             print(\"GitHub authentication failed. Skipping subsequent steps.\")\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error authenticating with GitHub: 401 {\"message\": \"Bad credentials\", \"documentation_url\": \"https://docs.github.com/rest\", \"status\": \"401\"}\n",
            "GitHub authentication failed. Skipping subsequent steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f116e6fd"
      },
      "source": [
        "# Task\n",
        "–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–π, –ø–æ–ø—ä–ª–Ω–∏ –∏ —Ä–∞–∑—à–∏—Ä–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–µ–Ω–∏—è –∫–æ–¥, –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏ –∏ –¥–∞–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ-–Ω–∞—Ç–∞—Ç—ä—à–Ω–æ –∏–∑–≥—Ä–∞–∂–¥–∞–Ω–µ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f5e9044"
      },
      "source": [
        "## –ü–æ–¥–æ–±—Ä—è–≤–∞–Ω–µ –Ω–∞ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ—Ç–æ –Ω–∞ —Ç–æ–∫–µ–Ω–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è—Ç–∞\n",
        "\n",
        "### Subtask:\n",
        "–©–µ –ø—Ä–µ—Ä–∞–±–æ—Ç—è –∑–∞—Ä–µ–∂–¥–∞–Ω–µ—Ç–æ –Ω–∞ GitHub –∏ Gemini —Ç–æ–∫–µ–Ω–∏—Ç–µ, –∫–∞—Ç–æ —Å–µ —É–≤–µ—Ä—è, —á–µ —Å–∞ –Ω–∞–ª–∏—á–Ω–∏ –ø—Ä–µ–¥–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–∞ –∫–ª–∞—Å–∞ `NovZhivot` –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–∞–Ω–µ—Ç–æ –Ω–∞ Gemini API. –©–µ –¥–æ–±–∞–≤—è –ø–æ-—è—Å–Ω–∏ —Å—ä–æ–±—â–µ–Ω–∏—è –∑–∞ –≥—Ä–µ—à–∫–∞, –∞–∫–æ —Ç–æ–∫–µ–Ω–∏—Ç–µ –ª–∏–ø—Å–≤–∞—Ç –∏–ª–∏ —Å–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω–∏.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d474e89"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires ensuring that both the GitHub and Gemini API tokens are loaded correctly using `dotenv` at the beginning of the script, checked for validity, and that subsequent operations dependent on these tokens are conditional on their successful loading. I will implement steps 1-7 of the instructions in this code block, focusing on the token loading and validation logic and updating the main execution block and class initialization accordingly. I will also ensure the `ask_gemini` method checks if the `gemini_model` is configured.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8b2467",
        "outputId": "9362eb1d-6651-4941-d221-de24c2915d20"
      },
      "source": [
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import shutil\n",
        "from github import Github, GithubException, UnknownObjectException\n",
        "from git import Repo, GitCommandError\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import py_compile\n",
        "import ast\n",
        "import json\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load API keys and configuration from environment variables\n",
        "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "# 3. Add checks immediately after loading the environment variables\n",
        "github_token_valid = False\n",
        "if GITHUB_TOKEN and GITHUB_TOKEN != \"YOUR_GITHUB_TOKEN\" and GITHUB_TOKEN != \"your_github_token_here\":\n",
        "    github_token_valid = True\n",
        "else:\n",
        "    # 4. Print a clear error message if either token is missing or invalid\n",
        "    print(\"Error: GITHUB_TOKEN not found or is a placeholder. Please set a valid GITHUB_TOKEN environment variable in the .env file.\")\n",
        "\n",
        "gemini_api_key_valid = False\n",
        "if GEMINI_API_KEY and GEMINI_API_KEY != \"YOUR_GEMINI_API_KEY\" and GEMINI_API_KEY != \"your_gemini_api_key_here\":\n",
        "    gemini_api_key_valid = True\n",
        "else:\n",
        "     # 4. Print a clear error message if either token is missing or invalid\n",
        "     print(\"Error: GEMINI_API_KEY not found or is a placeholder. Please set a valid GEMINI_API_KEY environment variable in the .env file.\")\n",
        "\n",
        "\n",
        "# 5. Wrap the genai.configure() call and genai.GenerativeModel() instantiation\n",
        "gemini_model = None # Initialize to None\n",
        "if gemini_api_key_valid:\n",
        "    try:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        # Choose a model, e.g., 'gemini-pro' or 'gemini-1.5-flash-latest'\n",
        "        # List available models: for m in genai.list_models(): print(m.name)\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        print(\"Gemini model configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring Gemini model: {e}\")\n",
        "        gemini_model = None # Ensure it's None if configuration fails\n",
        "else:\n",
        "    print(\"Gemini API calls will be skipped.\")\n",
        "\n",
        "\n",
        "GITHUB_USER  = \"AlexKitipov\"\n",
        "WORKDIR      = \"/content/nov_jivot_lab\"\n",
        "REPOS        = [\"finrl-test\", \"FractalNet\", \"third-repo\"]\n",
        "\n",
        "\n",
        "class NovZhivot:\n",
        "    def __init__(self, token, user, workdir, repos):\n",
        "        # 6. Update the __init__ method to also check if the passed token is valid\n",
        "        if not token or token == \"YOUR_GITHUB_TOKEN\" or token == \"your_github_token_here\":\n",
        "             raise ValueError(\"GitHub token is not provided or is a placeholder. Please set a valid token before initializing NovZhivot.\")\n",
        "\n",
        "        self.github = Github(token)\n",
        "        try:\n",
        "            self.user = self.github.get_user() # Get the authenticated user directly\n",
        "            print(f\"Authenticated as GitHub user: {self.user.login}\")\n",
        "            self.authenticated = True\n",
        "        except Exception as e:\n",
        "             print(f\"Error authenticating with GitHub: {e}\")\n",
        "             self.user = None # Set user to None if authentication fails\n",
        "             self.authenticated = False\n",
        "\n",
        "\n",
        "        self.workdir = workdir\n",
        "        self.repos = repos\n",
        "        self.processed_files = []\n",
        "        self.suggestions = {}\n",
        "        self.lab_repo_name = \"nov-jivot-lab\" # Define lab repo name\n",
        "        self.lab_repo_path = os.path.join(self.workdir, self.lab_repo_name)\n",
        "\n",
        "\n",
        "    def setup_workspace(self):\n",
        "        # Clean & create working directory\n",
        "        if os.path.exists(self.workdir):\n",
        "            shutil.rmtree(self.workdir)\n",
        "        os.makedirs(self.workdir, exist_ok=True)\n",
        "        print(f\"Workspace setup at {self.workdir}\")\n",
        "\n",
        "    def clone_repos(self):\n",
        "        # Clone each repo from your profile\n",
        "        print(\"Cloning repositories...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping cloning.\")\n",
        "            return\n",
        "\n",
        "        for name in self.repos:\n",
        "            url  = f\"https://github.com/{self.user.login}/{name}.git\"\n",
        "            dest = os.path.join(self.workdir, name)\n",
        "            try:\n",
        "                # Check if the directory already exists before cloning\n",
        "                if os.path.exists(dest):\n",
        "                    print(f\"Repository {name} already exists locally. Skipping clone.\")\n",
        "                    continue\n",
        "                Repo.clone_from(url, dest)\n",
        "                print(f\"Cloned {name} to {dest}\")\n",
        "            except GitCommandError as e:\n",
        "                print(f\"Error cloning {name}: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred cloning {name}: {e}\")\n",
        "\n",
        "\n",
        "    def collect_files(self, repo_path):\n",
        "        # Gather .py, .ipynb, README, LICENSE\n",
        "        files = []\n",
        "        for root, _, fnames in os.walk(repo_path):\n",
        "            for fn in fnames:\n",
        "                if fn.endswith((\".py\", \".ipynb\", \"README.md\", \"LICENSE\")):\n",
        "                    files.append(os.path.join(root, fn))\n",
        "        return files\n",
        "\n",
        "    def analyze_code_details(self, file_path: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a code file to extract details like imports, functions, and documentation.\n",
        "\n",
        "        Args:\n",
        "            file_path: The path to the file to analyze.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing extracted information.\n",
        "        \"\"\"\n",
        "        analysis_results = {\n",
        "            \"file_path\": file_path,\n",
        "            \"file_type\": os.path.splitext(file_path)[1],\n",
        "            \"imports\": [],\n",
        "            \"functions_classes\": [],\n",
        "            \"documentation\": [],\n",
        "            \"analysis_error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "            analysis_results[\"content_preview\"] = content[:500] + \"...\" if len(content) > 500 else content\n",
        "\n",
        "            if file_path.endswith(\".py\"):\n",
        "                try:\n",
        "                    tree = ast.parse(content)\n",
        "                    for node in ast.walk(tree):\n",
        "                        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
        "                            for alias in (node.names if isinstance(node, ast.Import) else node.names):\n",
        "                                analysis_results[\"imports\"].append(alias.name)\n",
        "                        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
        "                            analysis_results[\"functions_classes\"].append(f\"{node.__class__.__name__}: {node.name}\")\n",
        "                            # Extract docstrings\n",
        "                            if ast.get_docstring(node):\n",
        "                                analysis_results[\"documentation\"].append(f\"{node.name} docstring: {ast.get_docstring(node)[:200]}...\") # Limit docstring preview\n",
        "                except SyntaxError as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Syntax error during AST parsing: {e}\"\n",
        "                except Exception as e:\n",
        "                    analysis_results[\"analysis_error\"] = f\"Error during Python AST analysis: {e}\"\n",
        "            elif file_path.endswith(\".ipynb\"):\n",
        "                # Basic analysis for Jupyter notebooks (can be extended)\n",
        "                analysis_results[\"file_type\"] = \".ipynb\"\n",
        "                # Add logic to parse notebook structure and extract code cells\n",
        "                analysis_results[\"documentation\"].append(\"Jupyter Notebook analysis (basic)\")\n",
        "            elif file_path.endswith(\"README.md\"):\n",
        "                 analysis_results[\"file_type\"] = \"README.md\"\n",
        "                 analysis_results[\"documentation\"].append(f\"README content preview: {content[:500]}...\")\n",
        "            elif file_path.endswith(\"LICENSE\"):\n",
        "                 analysis_results[\"file_type\"] = \"LICENSE\"\n",
        "                 analysis_results[\"documentation\"].append(f\"LICENSE content preview: {content[:500]}...\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            analysis_results[\"analysis_error\"] = \"File not found.\"\n",
        "        except Exception as e:\n",
        "            analysis_results[\"analysis_error\"] = f\"Error reading or analyzing file: {e}\"\n",
        "\n",
        "        return analysis_results\n",
        "\n",
        "\n",
        "    def ask_gemini(self, prompt: str) -> str:\n",
        "        \"\"\"\n",
        "        Sends a prompt to Gemini API for analysis and improvement.\n",
        "        Explicitly asks Gemini for structured suggestions.\n",
        "\n",
        "        Args:\n",
        "            prompt: The prompt string including code snippet and analysis details.\n",
        "\n",
        "        Returns:\n",
        "            A string containing Gemini's response, which should include\n",
        "            the modified code and structured suggestions.\n",
        "        \"\"\"\n",
        "        # Access gemini_model from the global scope\n",
        "        global gemini_model\n",
        "\n",
        "        if gemini_model is None:\n",
        "            return \"# Gemini API not configured. Analysis skipped.\\n\" + prompt + \"\\n## Suggestions:\\n- Gemini API not available.\"\n",
        "\n",
        "        print(\"Calling Gemini API with detailed prompt...\")\n",
        "        try:\n",
        "            # Generate content using the Gemini model\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            # Return the generated text\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Gemini API: {e}\")\n",
        "            return f\"# Error calling Gemini API: {e}\\n\" + prompt + \"\\n## Suggestions:\\n- Error retrieving suggestions from Gemini.\"\n",
        "\n",
        "\n",
        "    def revive_code(self):\n",
        "        # Core pipeline: collect, analyze, prompt, process Gemini response, save\n",
        "        print(\"Starting code revival process...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "             print(\"GitHub user not authenticated. Skipping code revival.\")\n",
        "             return\n",
        "\n",
        "        for repo_name in self.repos:\n",
        "            base = os.path.join(self.workdir, repo_name)\n",
        "            if not os.path.exists(base):\n",
        "                print(f\"Repository {repo_name} not found in workspace. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            files = self.collect_files(base)\n",
        "            print(f\"Found {len(files)} files in {repo_name} to process.\")\n",
        "            for fpath in files:\n",
        "                print(f\"\\nüîÑ Processing {fpath}\")\n",
        "                try:\n",
        "                    # Analyze the file\n",
        "                    analysis_data = self.analyze_code_details(fpath)\n",
        "                    print(\"Analysis results:\", json.dumps(analysis_data, indent=2)) # Print analysis data\n",
        "\n",
        "                    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "                        snippet = f.read()\n",
        "\n",
        "                    # Include analysis data and specific instruction for structured suggestions\n",
        "                    prompt = f\"\"\"\n",
        "–ú–æ–ª—è, Gemini:\n",
        "- –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π —Ç–æ–∑–∏ –∫–æ–¥ –∏ –ø–æ–ø—Ä–∞–≤–∏ –≤—Å–∏—á–∫–∏ –≥—Ä–µ—à–∫–∏.\n",
        "- –ü—Ä–µ–¥–ª–æ–∂–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –¥–æ–±–∞–≤–∏ –ø–æ–¥—Ä–æ–±–Ω–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏.\n",
        "- –ê–∫–æ –ª–∏–ø—Å–≤–∞ README —Å–µ–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä–∞–π —è.\n",
        "- –ò–∑–ø–æ–ª–∑–≤–∞–π —Å–ª–µ–¥–Ω–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{json.dumps(analysis_data, indent=2)}\n",
        "\n",
        "–ö–æ–¥:\n",
        "```python\n",
        "{snippet}\n",
        "```\n",
        "\n",
        "–í –∫—Ä–∞—è –Ω–∞ —Ç–≤–æ—è –æ—Ç–≥–æ–≤–æ—Ä, –º–æ–ª—è, –¥–æ–±–∞–≤–∏ —Å–µ–∫—Ü–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –ø–æ–¥–æ–±—Ä–µ–Ω–∏—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω –≤–∏–¥ (–Ω–∞–ø—Ä. —Å–ø–∏—Å—ä–∫ —Å —Ç–æ—á–∫–∏) –ø–æ–¥ –∑–∞–≥–ª–∞–≤–∏–µ \"## Suggestions:\".\n",
        "\"\"\"\n",
        "\n",
        "                    gemini_response = self.ask_gemini(prompt)\n",
        "\n",
        "                    # Process Gemini's response to extract suggestions and updated code\n",
        "                    updated_code = gemini_response\n",
        "                    suggestions_text = \"No suggestions found.\"\n",
        "\n",
        "                    # Simple approach to find the suggestions section\n",
        "                    suggestions_marker = \"## Suggestions:\"\n",
        "                    if suggestions_marker in gemini_response:\n",
        "                        parts = gemini_response.split(suggestions_marker, 1)\n",
        "                        updated_code = parts[0].strip()\n",
        "                        suggestions_text = suggestions_marker + parts[1].strip()\n",
        "                    else:\n",
        "                         print(\"Suggestions marker not found in Gemini response.\")\n",
        "\n",
        "\n",
        "                    # Store suggestions\n",
        "                    relative_path = os.path.relpath(fpath, self.workdir)\n",
        "                    self.suggestions[relative_path] = suggestions_text\n",
        "                    print(f\"Extracted suggestions for {relative_path}.\")\n",
        "\n",
        "                    # Determine the output path. Append _revived before the extension.\n",
        "                    name, ext = os.path.splitext(fpath)\n",
        "                    out_path = f\"{name}_revived{ext}\"\n",
        "\n",
        "                    # Ensure the output directory exists\n",
        "                    out_dir = os.path.dirname(out_path)\n",
        "                    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "                    # Save the updated code and suggestions\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "                        out.write(updated_code)\n",
        "                        out.write(\"\\n\\n\") # Add a separator\n",
        "                        out.write(suggestions_text) # Append suggestions to the file\n",
        "\n",
        "                    self.processed_files.append(out_path)\n",
        "                    print(f\"Processed, saved updated code and suggestions to {out_path}\")\n",
        "\n",
        "                    # Optionally, save suggestions to a separate file\n",
        "                    suggestions_out_path = f\"{name}_revived_suggestions.md\"\n",
        "                    with open(suggestions_out_path, \"w\", encoding=\"utf-8\") as out_sugg:\n",
        "                        out_sugg.write(suggestions_text)\n",
        "                    print(f\"Saved suggestions to {suggestions_out_path}\")\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        # Simple syntax test for Python files\n",
        "        print(\"\\nValidating processed files...\")\n",
        "        for file in self.processed_files:\n",
        "            if file.endswith(\".py\"):\n",
        "                try:\n",
        "                    py_compile.compile(file, doraise=True)\n",
        "                    print(f\"‚úÖ {file} syntax OK\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå {file} syntax error: {e}\")\n",
        "            else:\n",
        "                print(f\"‚è≠Ô∏è Skipping syntax check for non-Python file: {file}\")\n",
        "\n",
        "\n",
        "    def visualize(self):\n",
        "        # Count of revived files\n",
        "        counts = len(self.processed_files)\n",
        "        print(f\"\\nTotal files processed and revived: {counts}\")\n",
        "        if counts > 0:\n",
        "            plt.figure(figsize=(4, 3))\n",
        "            plt.bar([\"Revived Files\"], [counts], color='skyblue')\n",
        "            plt.title(\"Nov Zhivot ‚Äì Files Revived\")\n",
        "            plt.ylabel(\"Number of Files\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No files were processed to visualize.\")\n",
        "\n",
        "\n",
        "    def commit_push(self):\n",
        "        print(\"\\nPreparing to commit and push to GitHub...\")\n",
        "        if not self.authenticated or self.user is None:\n",
        "            print(\"GitHub user not authenticated. Skipping commit and push.\")\n",
        "            return\n",
        "\n",
        "        # 1. Ensure the local repository exists and is initialized\n",
        "        if not os.path.exists(self.lab_repo_path):\n",
        "            print(f\"Initializing new local repository at {self.lab_repo_path}\")\n",
        "            Repo.init(self.lab_repo_path)\n",
        "\n",
        "        try:\n",
        "            repo = Repo(self.lab_repo_path)\n",
        "\n",
        "            # Add all processed files and suggestion files to the staging area\n",
        "            repo.git.add(A=True)\n",
        "\n",
        "            # Check if there are any changes to commit\n",
        "            if repo.index.diff(None) or repo.untracked_files:\n",
        "                print(\"Changes detected. Committing...\")\n",
        "                repo.index.commit(f\"‚ú® Revival commit by –ù–æ–≤ –ñ–∏–≤–æ—Ç - {datetime.utcnow().isoformat()}Z\")\n",
        "                print(\"Committed changes to local nov-jivot-lab repo.\")\n",
        "\n",
        "                # 2. Ensure the remote repository exists on GitHub\n",
        "                print(f\"Checking for remote repository '{self.lab_repo_name}' on GitHub...\")\n",
        "                try:\n",
        "                    remote_repo = self.user.get_repo(self.lab_repo_name)\n",
        "                    print(f\"Remote repository '{self.lab_repo_name}' found.\")\n",
        "                except UnknownObjectException:\n",
        "                    print(f\"Remote repository '{self.lab_repo_name}' not found. Creating it...\")\n",
        "                    try:\n",
        "                        remote_repo = self.user.create_repo(\n",
        "                            self.lab_repo_name,\n",
        "                            description=\"Revived code and suggestions from personal projects by Nov Zhivot AI.\",\n",
        "                            private=False # Set to True if you want a private repository\n",
        "                        )\n",
        "                        print(f\"Remote repository '{self.lab_repo_name}' created successfully.\")\n",
        "                        print(\"Please ensure your GitHub token has the 'public_repo' or 'repo' scope to create repositories.\")\n",
        "                    except GithubException as e:\n",
        "                        print(f\"Error creating remote repository '{self.lab_repo_name}': {e}\")\n",
        "                        print(\"Please ensure your GitHub token has the necessary permissions (e.g., 'public_repo' or 'repo') to create repositories.\")\n",
        "                        return # Stop if repo creation fails\n",
        "                except Exception as e:\n",
        "                    print(f\"An unexpected error occurred while checking/creating remote repository: {e}\")\n",
        "                    return\n",
        "\n",
        "\n",
        "                # 3. Configure the local repository's remote URL\n",
        "                remote_name = \"origin\"\n",
        "                remote_url = f\"https://github.com/{self.user.login}/{self.lab_repo_name}.git\"\n",
        "\n",
        "                # Check if remote already exists and update URL if necessary\n",
        "                if remote_name in [remote.name for remote in repo.remotes]:\n",
        "                     origin = repo.remote[remote_name]\n",
        "                     if origin.url != remote_url:\n",
        "                         print(f\"Updating remote '{remote_name}' URL to: {remote_url}\")\n",
        "                         origin.set_url(remote_url)\n",
        "                     print(f\"Remote '{remote_name}' already exists.\")\n",
        "                else:\n",
        "                    print(f\"Adding remote '{remote_name}' with URL: {remote_url}\")\n",
        "                    origin = repo.create_remote(remote_name, remote_url)\n",
        "\n",
        "                # Set the origin URL to include the token for pushing\n",
        "                # Note: Embedding token in URL is not recommended for security in persistent environments.\n",
        "                # A better approach is using SSH keys or GitHub CLI with authentication.\n",
        "                # For this Colab example, we'll use the token in the URL for simplicity, but be aware of the security implications.\n",
        "                # Ensure the URL includes the token for authentication when pushing\n",
        "                auth_remote_url = f\"https://{self.user.login}:{self.github.access_token}@github.com/{self.user.login}/{self.lab_repo_name}.git\"\n",
        "                origin.set_url(auth_remote_url)\n",
        "                print(f\"Remote URL set for authentication.\")\n",
        "\n",
        "\n",
        "                # 4. Implement the logic to push changes\n",
        "                print(f\"Pushing to remote '{remote_name}'...\")\n",
        "                print(\"Please ensure your GitHub token has push permissions to the repository.\")\n",
        "                # Push to the remote repository. Create 'main' branch if it doesn't exist.\n",
        "                # Use 'main' as the default branch name.\n",
        "                # Instruction 5 Note: Pushing to 'main' as per previous steps. Creating new branches per revival\n",
        "                # could be implemented here for better history management.\n",
        "                try:\n",
        "                    # Fetch before pushing to potentially avoid conflicts if the remote repo was just created\n",
        "                    # and GitHub added an initial commit (like README).\n",
        "                    try:\n",
        "                         origin.fetch()\n",
        "                         print(\"Fetched from remote.\")\n",
        "                    except GitCommandError as e:\n",
        "                         print(f\"Could not fetch from remote (might be a new empty repo): {e}\")\n",
        "\n",
        "\n",
        "                    # Push the current HEAD (latest commit) to the 'main' branch on the remote.\n",
        "                    # Use force=True for simplicity in this lab to overwrite potential initial commits\n",
        "                    # or diverging histories. Be very cautious with force=True in real projects.\n",
        "                    push_info = origin.push(refspec='HEAD:refs/heads/main', force=True)\n",
        "\n",
        "                    # Check push results for errors\n",
        "                    if push_info:\n",
        "                        for info in push_info:\n",
        "                            if info.summary.startswith('!'): # Indicates an error\n",
        "                                print(f\"Push failed: {info.summary}\")\n",
        "                                print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "                            else:\n",
        "                                print(f\"Successfully pushed: {info.summary}\")\n",
        "                    else:\n",
        "                        print(\"Push completed with no detailed info.\")\n",
        "\n",
        "                    print(\"Successfully pushed to GitHub.\")\n",
        "                except GitCommandError as e:\n",
        "                    print(f\"Error during git push: {e}\")\n",
        "                    print(\"Please ensure the 'nov-jivot-lab' repository exists on GitHub and your token has push permissions.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"An unexpected error occurred during push: {e}\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"No changes to commit.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during commit or push preparation: {e}\")\n",
        "\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # 7. Ensure both GITHUB_TOKEN and GEMINI_API_KEY were successfully loaded and validated\n",
        "    if not github_token_valid:\n",
        "        print(\"Cannot proceed without a valid GitHub token.\")\n",
        "    elif not gemini_api_key_valid:\n",
        "         print(\"Cannot proceed with Gemini API calls without a valid Gemini API key.\")\n",
        "         # Proceed with other steps that don't require Gemini if desired,\n",
        "         # but for this workflow, both are essential.\n",
        "    else:\n",
        "        # Pass the loaded tokens to the class\n",
        "        try:\n",
        "            model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "\n",
        "            # 8. Only proceed if GitHub authentication was successful\n",
        "            if model.authenticated:\n",
        "                 model.setup_workspace()\n",
        "                 model.clone_repos()\n",
        "                 # If gemini_model is None, model.revive_code() will skip Gemini calls (already handled)\n",
        "                 model.revive_code()\n",
        "                 model.validate()\n",
        "                 model.visualize()\n",
        "                 model.commit_push()\n",
        "            else:\n",
        "                 print(\"GitHub authentication failed. Skipping subsequent steps.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Initialization error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during execution: {e}\")\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: GEMINI_API_KEY not found or is a placeholder. Please set a valid GEMINI_API_KEY environment variable in the .env file.\n",
            "Gemini API calls will be skipped.\n",
            "Cannot proceed with Gemini API calls without a valid Gemini API key.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15b09901"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed because the `GEMINI_API_KEY` was still a placeholder. I need to update the `.env` file with a valid Gemini API key. Since I cannot directly edit the file system, I will provide the code to create the `.env` file again, but this time with a comment indicating where the user should replace the placeholder with their actual key. This directly addresses the feedback from the previous execution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "363456ea",
        "outputId": "284e9cab-70c8-46f5-f94d-100fc7042786"
      },
      "source": [
        "# Create or overwrite a .env file in the root directory and add the GEMINI_API_KEY\n",
        "# IMPORTANT: Replace 'your_gemini_api_key_here' with your actual Gemini API key\n",
        "env_file_path = '/content/.env'\n",
        "with open(env_file_path, 'w') as f:\n",
        "    f.write(\"GEMINI_API_KEY='your_gemini_api_key_here'\\n\") # Replace with your actual key\n",
        "    # Also add a placeholder for GITHUB_TOKEN for clarity, although it was loaded previously\n",
        "    f.write(\"GITHUB_TOKEN='your_github_token_here'\\n\") # Replace with your actual GitHub token\n",
        "\n",
        "print(f\".env file created/updated at {env_file_path} with placeholder keys.\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".env file created/updated at /content/.env with placeholder keys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e25f039"
      },
      "source": [
        "**Reasoning**:\n",
        "I have created the `.env` file with placeholder keys. Now I need to run the main execution block again. This will load the updated `.env` file, validate the tokens, configure the Gemini model (if the key is valid), and attempt to proceed with the NovZhivot workflow. This addresses the core of the subtask by re-attempting the token loading and validation after the `.env` file has been prepared.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3606abec",
        "outputId": "16eaa583-af8f-44c3-b5ee-7e45bbf0af50"
      },
      "source": [
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure both GITHUB_TOKEN and GEMINI_API_KEY were successfully loaded and validated\n",
        "    # GITHUB_TOKEN and GEMINI_API_KEY are loaded via dotenv at the beginning of the script\n",
        "    # and validated immediately after loading.\n",
        "\n",
        "    if not github_token_valid:\n",
        "        print(\"Cannot proceed without a valid GitHub token.\")\n",
        "    elif not gemini_api_key_valid:\n",
        "         print(\"Cannot proceed with Gemini API calls without a valid Gemini API key.\")\n",
        "         # Proceed with other steps that don't require Gemini if desired,\n",
        "         # but for this workflow, both are essential.\n",
        "    else:\n",
        "        # Pass the loaded tokens to the class\n",
        "        try:\n",
        "            model = NovZhivot(GITHUB_TOKEN, GITHUB_USER, WORKDIR, REPOS)\n",
        "\n",
        "            # Only proceed if GitHub authentication was successful\n",
        "            if model.authenticated:\n",
        "                 model.setup_workspace()\n",
        "                 model.clone_repos()\n",
        "                 # If gemini_model is None, model.revive_code() will skip Gemini calls (already handled)\n",
        "                 model.revive_code()\n",
        "                 model.validate()\n",
        "                 model.visualize()\n",
        "                 model.commit_push()\n",
        "            else:\n",
        "                 print(\"GitHub authentication failed. Skipping subsequent steps.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Initialization error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during execution: {e}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot proceed with Gemini API calls without a valid Gemini API key.\n"
          ]
        }
      ]
    }
  ]
}